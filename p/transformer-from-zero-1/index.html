<!DOCTYPE html>
<html lang="en-us" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='‰ªé 0 ÂºÄÂßãÂ≠¶‰π† Transformer ‰∏äÁØáÔºöTransformer Êê≠Âª∫‰∏éÁêÜËß£'><title>‰ªé 0 ÂºÄÂßãÂ≠¶‰π† Transformer ‰∏äÁØáÔºöTransformer Êê≠Âª∫‰∏éÁêÜËß£</title>

<link rel='canonical' href='https://lilithsangreal.com/p/transformer-from-zero-1/'>

<link rel="stylesheet" href="/scss/style.min.ac77dcf8b111b51da39a92990f431923f210f3876d85798a2125667f96dc33a4.css"><meta property='og:title' content='‰ªé 0 ÂºÄÂßãÂ≠¶‰π† Transformer ‰∏äÁØáÔºöTransformer Êê≠Âª∫‰∏éÁêÜËß£'>
<meta property='og:description' content='‰ªé 0 ÂºÄÂßãÂ≠¶‰π† Transformer ‰∏äÁØáÔºöTransformer Êê≠Âª∫‰∏éÁêÜËß£'>
<meta property='og:url' content='https://lilithsangreal.com/p/transformer-from-zero-1/'>
<meta property='og:site_name' content='Lilith Sangreal'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:published_time' content='2019-12-02T00:00:00&#43;00:00'/><meta property='article:modified_time' content='2019-12-02T00:00:00&#43;00:00'/><meta property='og:image' content='https://lilithsangreal.com/p/transformer-from-zero-1/the_transformer.png' />
<meta name="twitter:title" content="‰ªé 0 ÂºÄÂßãÂ≠¶‰π† Transformer ‰∏äÁØáÔºöTransformer Êê≠Âª∫‰∏éÁêÜËß£">
<meta name="twitter:description" content="‰ªé 0 ÂºÄÂßãÂ≠¶‰π† Transformer ‰∏äÁØáÔºöTransformer Êê≠Âª∫‰∏éÁêÜËß£"><meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content='https://lilithsangreal.com/p/transformer-from-zero-1/the_transformer.png' />
    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/images/avatar_hub2e5e0ee896a35ef30e87da7e9f71a6e_16593_300x0_resize_q75_box.jpeg" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
                    <span class="emoji">üåû</span>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">Lilith Sangreal</a></h1>
            <h2 class="site-description">Êö¥È£éÈõ®Êù•‰∏¥ÔºåÁîµÈó™ÂèàÈõ∑È∏£„ÄÇ</h2>
        </div>
    </header><ol class="social-menu">
            
                <li>
                    <a 
                        href='https://github.com/L1l1thLY'
                        target="_blank"
                        title="GitHub"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M9 19c-4.3 1.4 -4.3 -2.5 -6 -3m12 5v-3.5c0 -1 .1 -1.4 -.5 -2c2.8 -.3 5.5 -1.4 5.5 -6a4.6 4.6 0 0 0 -1.3 -3.2a4.2 4.2 0 0 0 -.1 -3.2s-1.1 -.3 -3.5 1.3a12.3 12.3 0 0 0 -6.2 0c-2.4 -1.6 -3.5 -1.3 -3.5 -1.3a4.2 4.2 0 0 0 -.1 3.2a4.6 4.6 0 0 0 -1.3 3.2c0 4.6 2.7 5.7 5.5 6c-.6 .6 -.6 1.2 -.5 2v3.5" />
</svg>



                        
                    </a>
                </li>
            
        </ol><ol class="menu" id="main-menu">
        
        
        

        <li >
            <a href='/' target="_blank">
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>Home</span>
            </a>
        </li>
        
        

        <li >
            <a href='/about/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="7" r="4" />
  <path d="M6 21v-2a4 4 0 0 1 4 -4h4a4 4 0 0 1 4 4v2" />
</svg>



                
                <span>About</span>
            </a>
        </li>
        
        

        <li >
            <a href='/archives/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>Archives</span>
            </a>
        </li>
        
        

        <li >
            <a href='/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>Search</span>
            </a>
        </li>
        
        

        <li >
            <a href='/links/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5" />
  <path d="M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5" />
</svg>



                
                <span>Links</span>
            </a>
        </li>
        

        <div class="menu-bottom-section">
            
            
                <li id="dark-mode-toggle">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <span>Dark Mode</span>
                </li>
            
        </div>
    </ol>
</aside>
<main class="main full-width">
    <article class="has-image main-article">
    <header class="article-header">
        <div class="article-image">
            <a href="/p/transformer-from-zero-1/">
                <img src="/p/transformer-from-zero-1/the_transformer_hu9dc15172e42e840ef18a078a4efb196f_44824_800x0_resize_box_3.png"
                        srcset="/p/transformer-from-zero-1/the_transformer_hu9dc15172e42e840ef18a078a4efb196f_44824_800x0_resize_box_3.png 800w, /p/transformer-from-zero-1/the_transformer_hu9dc15172e42e840ef18a078a4efb196f_44824_1600x0_resize_box_3.png 1600w"
                        width="800" 
                        height="209" 
                        loading="lazy"
                        alt="Featured image of post ‰ªé 0 ÂºÄÂßãÂ≠¶‰π† Transformer ‰∏äÁØáÔºöTransformer Êê≠Âª∫‰∏éÁêÜËß£" />
                
            </a>
        </div>
    

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/nlp/" >
                NLP
            </a>
        
            <a href="/categories/deep-learning/" >
                Deep Learning
            </a>
        
            <a href="/categories/%E4%BB%8E-0-%E5%BC%80%E5%A7%8B-transformer/" >
                ‰ªé 0 ÂºÄÂßã Transformer
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/p/transformer-from-zero-1/">‰ªé 0 ÂºÄÂßãÂ≠¶‰π† Transformer ‰∏äÁØáÔºöTransformer Êê≠Âª∫‰∏éÁêÜËß£</a>
        </h2>
    
        
        <h3 class="article-subtitle">
            ‰ªé 0 ÂºÄÂßãÂ≠¶‰π† Transformer ‰∏äÁØáÔºöTransformer Êê≠Âª∫‰∏éÁêÜËß£
        </h3>
        
    </div>

    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Dec 02, 2019</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    11 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>
</header>

    <section class="article-content">
    
    
    <h1 id="‰ªé-0-ÂºÄÂßãÂ≠¶‰π†-transformer-‰∏äÁØátransformer-Êê≠Âª∫‰∏éÁêÜËß£">‰ªé 0 ÂºÄÂßãÂ≠¶‰π† Transformer ‰∏äÁØáÔºöTransformer Êê≠Âª∫‰∏éÁêÜËß£</h1>
<!-- raw HTML omitted -->
<ul>
<li><a class="link" href="#%e4%bb%8e-0-%e5%bc%80%e5%a7%8b%e5%ad%a6%e4%b9%a0-transformer-%e4%b8%8a%e7%af%87transformer-%e6%90%ad%e5%bb%ba%e4%b8%8e%e7%90%86%e8%a7%a3" >‰ªé 0 ÂºÄÂßãÂ≠¶‰π† Transformer ‰∏äÁØáÔºöTransformer Êê≠Âª∫‰∏éÁêÜËß£</a>
<ul>
<li><a class="link" href="#1-%e5%89%8d%e8%a8%80" >1. ÂâçË®Ä</a></li>
<li><a class="link" href="#2-%e5%8f%82%e8%80%83%e4%bb%a3%e7%a0%81%e6%96%87%e7%ab%a0%e5%8f%8a%e9%83%a8%e5%88%86%e6%8f%92%e5%9b%be%e6%9d%a5%e6%ba%90" >2. ÂèÇËÄÉ‰ª£Á†Å„ÄÅÊñáÁ´†ÂèäÈÉ®ÂàÜÊèíÂõæÊù•Ê∫ê</a></li>
<li><a class="link" href="#3-%e5%9c%a8%e5%bc%80%e5%a7%8b%e5%89%8d%e7%9a%84%e6%8e%a8%e8%8d%90%e4%ba%86%e8%a7%a3" >3. Âú®ÂºÄÂßãÂâçÁöÑÊé®Ëçê‰∫ÜËß£</a>
<ul>
<li><a class="link" href="#31-%e5%be%aa%e7%8e%af%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9crnn" >3.1. Âæ™ÁéØÁ•ûÁªèÁΩëÁªúÔºàRNNÔºâ</a></li>
<li><a class="link" href="#32-%e5%9f%ba%e4%ba%8e%e7%bc%96%e7%a0%81-%e8%a7%a3%e7%a0%81encoder-decoder%e7%9a%84%e5%ba%8f%e5%88%97%e5%88%b0%e5%ba%8f%e5%88%97sequence2sequence%e6%a8%a1%e5%9e%8b" >3.2. Âü∫‰∫éÁºñÁ†Å-Ëß£Á†ÅÔºàencoder-decoderÔºâÁöÑÂ∫èÂàóÂà∞Â∫èÂàóÔºàsequence2sequenceÔºâÊ®°Âûã</a></li>
<li><a class="link" href="#33-%e6%b3%a8%e6%84%8f%e5%8a%9b%e6%9c%ba%e5%88%b6" >3.3. Ê≥®ÊÑèÂäõÊú∫Âà∂</a></li>
<li><a class="link" href="#34-%e8%af%8d%e5%b5%8c%e5%85%a5word-embedding" >3.4. ËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâ</a></li>
</ul>
</li>
<li><a class="link" href="#4-%e5%88%9d%e6%8e%a2-transformer" >4. ÂàùÊé¢ Transformer</a></li>
<li><a class="link" href="#5-%e5%9f%ba%e7%a1%80%e7%ae%97%e6%b3%95%e5%92%8c%e6%a8%a1%e5%9d%97" >5. Âü∫Á°ÄÁÆóÊ≥ïÂíåÊ®°Âùó</a>
<ul>
<li><a class="link" href="#51-%e4%bd%8d%e7%bd%ae%e7%bc%96%e7%a0%81positional-encoding" >5.1. ‰ΩçÁΩÆÁºñÁ†ÅÔºàPositional encodingÔºâ</a></li>
<li><a class="link" href="#52-%e6%b3%a8%e6%84%8f%e5%8a%9b%e6%9c%ba%e5%88%b6" >5.2. Ê≥®ÊÑèÂäõÊú∫Âà∂</a>
<ul>
<li><a class="link" href="#521-%e8%ae%a1%e7%ae%97%e6%ad%a5%e9%aa%a4%e7%bb%86%e8%8a%82" >5.2.1. ËÆ°ÁÆóÊ≠•È™§ÁªÜËäÇ</a></li>
<li><a class="link" href="#522-%e4%bd%bf%e7%94%a8%e5%90%91%e9%87%8f%e5%8c%96%e6%9d%a5%e6%8f%90%e5%8d%87%e6%95%88%e7%8e%87" >5.2.2. ‰ΩøÁî®ÂêëÈáèÂåñÊù•ÊèêÂçáÊïàÁéá</a></li>
<li><a class="link" href="#523-%e5%a6%82%e4%bd%95%e4%bd%9c%e4%b8%ba%e8%87%aa%e6%b3%a8%e6%84%8f%e5%8a%9b%e4%bd%bf%e7%94%a8" >5.2.3. Â¶Ç‰Ωï‰Ωú‰∏∫Ëá™Ê≥®ÊÑèÂäõ‰ΩøÁî®</a></li>
</ul>
</li>
<li><a class="link" href="#53-%e9%81%ae%e6%8c%a1-mask" >5.3. ÈÅÆÊå° Mask</a>
<ul>
<li><a class="link" href="#531-%e5%a1%ab%e5%85%85%e9%81%ae%e6%8c%a1" >5.3.1. Â°´ÂÖÖÈÅÆÊå°</a></li>
<li><a class="link" href="#532-%e5%89%8d%e7%9e%bb%e9%81%ae%e6%8c%a1look-ahead-mask" >5.3.2. ÂâçÁûªÈÅÆÊå°Ôºàlook-ahead maskÔºâ</a></li>
</ul>
</li>
<li><a class="link" href="#54-%e5%a4%9a%e5%a4%b4%e6%b3%a8%e6%84%8f%e5%8a%9bmulti-head-attention" >5.4. Â§öÂ§¥Ê≥®ÊÑèÂäõÔºàMulti-head attentionÔºâ</a>
<ul>
<li><a class="link" href="#541-%e4%bb%a3%e7%a0%81%e5%88%86%e6%9e%90" >5.4.1. ‰ª£Á†ÅÂàÜÊûê</a></li>
</ul>
</li>
<li><a class="link" href="#55-%e7%82%b9%e5%bc%8f%e5%89%8d%e9%a6%88%e7%bd%91%e7%bb%9cpoint-wise-feed-forward-network" >5.5. ÁÇπÂºèÂâçÈ¶àÁΩëÁªúÔºàPoint wise feed forward networkÔºâ</a></li>
</ul>
</li>
<li><a class="link" href="#6-%e7%bc%96%e7%a0%81%e5%99%a8%e8%a7%a3%e7%a0%81%e5%99%a8" >6. ÁºñÁ†ÅÂô®Ëß£Á†ÅÂô®</a>
<ul>
<li><a class="link" href="#61-%e7%bc%96%e7%a0%81%e5%99%a8%e5%b1%82" >6.1. ÁºñÁ†ÅÂô®Â±Ç</a></li>
<li><a class="link" href="#62-%e8%a7%a3%e7%a0%81%e5%99%a8%e5%b1%82" >6.2. Ëß£Á†ÅÂô®Â±Ç</a></li>
<li><a class="link" href="#63-%e7%bc%96%e7%a0%81%e5%99%a8" >6.3. ÁºñÁ†ÅÂô®</a></li>
<li><a class="link" href="#64-%e8%a7%a3%e7%a0%81%e5%99%a8" >6.4. Ëß£Á†ÅÂô®</a></li>
</ul>
</li>
<li><a class="link" href="#7-%e5%88%9b%e5%bb%ba-transformer" >7. ÂàõÂª∫ Transformer</a></li>
<li><a class="link" href="#8-%e5%b0%8f%e7%bb%93" >8. Â∞èÁªì</a></li>
</ul>
</li>
</ul>
<!-- raw HTML omitted -->
<h2 id="1-ÂâçË®Ä">1. ÂâçË®Ä</h2>
<p>Êú¨ÊñáÁ´†ÁªìÂêà‰ª£Á†ÅËÆ≤Ëß£Â¶Ç‰Ωï‰ΩøÁî® Tensorflow <strong>‰ªéÈõ∂ÂºÄÂßãÂ≠¶‰π†ÁêÜËß£ÂèäÊê≠Âª∫‰∏Ä‰∏™Transformer</strong>ÔºåÊú¨Êñá‰ª£Á†ÅÂü∫‰∫éTensorflow 2.0ÁâàÊú¨ÔºåËã•‰ΩøÁî®ÂÖ∂‰ªñÁâàÊú¨ÊàñPytorch‰∫¶‰∏çÂ¶®ÂèÇËÄÉ„ÄÇ</p>
<p>Áõ∏ËæÉ‰∫é Tensorflow ÂÆòÊñπÊåáÂçóÔºåÊú¨ÊñáÂ∞ÜÂØπÊ®°ÂùóÁªÜËäÇÂíå‰ΩøÁî®ËøõË°åÊõ¥Á≤æÁªÜÁöÑËÆ≤Ëß£ÔºõÂ∞ÜÂØπ‰ª£Á†ÅÊûÑÂª∫ËøáÁ®ã‰∏≠<strong>‰ª£Á†ÅËøõË°åÈÄêË°åËß£Èáä</strong>‰ª•Âèä<strong>Ëá™Ê≥®ÊÑèÂäõÊú∫Âà∂Á≠âÁªÜËäÇËÆæËÆ°</strong>ËøõË°åËÆ≤Ëß£„ÄÇÈô§Ê≠§‰πãÂ§ñÔºå‰πüÂä†ÂÖ•‰∫ÜÁ¨îËÄÖÂØπ‰∫é Transformer ÁªÜËäÇÈÉ®ÂàÜÁöÑ‰∏Ä‰∫õ<strong>‰∏™‰∫∫ÁñëÊÉëÂíåÁêÜËß£</strong>„ÄÇÁÆÄËÄåË®Ä‰πãÔºåÊòØËûçÂêà‰∫Ü‰ª£Á†ÅÊåáÂçóÂíåÂéüÁêÜÁ≤æËÆ≤ÁöÑ‰∏ÄÁØáÊñáÁ´†ÔºåÂäõÊ±ÇÂ∞ÜÁ¨îËÄÖÂØπ‰∫é Transformer ÁöÑÁêÜËß£Á≤æÁ≤π‰∫é‰∏ÄÁØáÊñáÁ´†ÔºåÊú¨‰∫∫ÊâçÁñèÂ≠¶ÊµÖÔºåÊ¨¢ËøéÊâπËØÑÊåáÊ≠£„ÄÇ</p>
<p>Êï¥‰∏™ÊñáÁ´†ÁªìÊûÑÂèÇËÄÉ Tensorflow ÂÆòÊñπÊåáÂçóÔºåÊåâÁÖßËá™Â∫ïÂêë‰∏äÁöÑÈ°∫Â∫èÊù•ÈÄêÊ∏êÊê≠Âª∫‰∏Ä‰∏™Áî®‰∫é<strong>Â∞ÜËë°ËêÑÁâôËØ≠ÁøªËØë‰∏∫Ëã±ËØ≠ÁöÑTransformerÊ®°Âûã</strong>ÔºöÂÖà‰ªéÊúÄÂü∫Êú¨ÁöÑÁÆóÊ≥ïÊ®°ÂùóÂÆûÁé∞ÔºåÁÑ∂ÂêéÁªÑË£Ö„ÄÇÂú®ÁªÑË£ÖËøáÁ®ã‰∏≠ËÆ≤Ëß£ÂêÑ‰∏™Â≠êÊ®°Âùó‰∫ßÁîüÁöÑ‰ΩúÁî®„ÄÇ</p>
<h2 id="2-ÂèÇËÄÉ‰ª£Á†ÅÊñáÁ´†ÂèäÈÉ®ÂàÜÊèíÂõæÊù•Ê∫ê">2. ÂèÇËÄÉ‰ª£Á†Å„ÄÅÊñáÁ´†ÂèäÈÉ®ÂàÜÊèíÂõæÊù•Ê∫ê</h2>
<p>Êú¨ÊñáÂ§ßÈáèÂèÇËÄÉÂèä‰ΩøÁî®‰ªñ‰∫∫ÊñáÁ´†ÂíåÂÆòÊñπÊñáÊ°£‰∏≠‰ª£Á†ÅÂíåÂõæÁâáÔºåÂú®Ê≠§Ë°®Á§∫ÊÑüË∞¢Ôºö</p>
<ul>
<li><a class="link" href="https://jalammar.github.io/illustrated-transformer/"  target="_blank" rel="noopener"
    >The Illustrated Transformer</a></li>
<li><a class="link" href="https://tensorflow.google.cn/tutorials/text/transformer"  target="_blank" rel="noopener"
    >Transformer model for language understanding</a></li>
<li><a class="link" href="https://tensorflow.google.cn/api_docs/python/tf"  target="_blank" rel="noopener"
    >TensorFlow Core r2.0 API</a></li>
<li><a class="link" href="https://tensorflow.google.cn/datasets"  target="_blank" rel="noopener"
    >Datasets v1.3.0 API</a></li>
</ul>
<h2 id="3-Âú®ÂºÄÂßãÂâçÁöÑÊé®Ëçê‰∫ÜËß£">3. Âú®ÂºÄÂßãÂâçÁöÑÊé®Ëçê‰∫ÜËß£</h2>
<h3 id="31-Âæ™ÁéØÁ•ûÁªèÁΩëÁªúrnn">3.1. Âæ™ÁéØÁ•ûÁªèÁΩëÁªúÔºàRNNÔºâ</h3>
<p>RNNÊòØ‰∏ÄÁßçÂèØÁî®‰∫éÊäΩÂèñÂ∫èÂàóÊï∞ÊçÆÁâπÂæÅÁöÑÁ•ûÁªèÁΩëÁªúÁªìÊûÑÔºå‰∏Ä‰∏™ÊúÄÂü∫Êú¨ÁöÑRNNÊòØÈùûÂ∏∏ÂÆπÊòìÁêÜËß£ÁöÑÔºåÁõ∏ÂΩì‰∫é NLP È¢ÜÂüüÁöÑ ‚ÄúHello world‚Äú„ÄÇÂæàÂ§ö NLP È¢ÜÂüüÁöÑÁü•ËØÜÁÇπÔºàÂ¶ÇÊú¨ÊñáÂèØËÉΩÁî®Âà∞ÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂‰∏éËá™Ê≥®ÊÑèÂäõÊú∫Âà∂„ÄÅencoder-decoderÊû∂ÊûÑÔºâÁöÑÁõ∏ÂÖ≥ÊñáÁ´†ÂæàÂ§öÈÉΩ‰ºö‰ΩøÁî®‰∏Ä‰∏™ÊúÄÂü∫Êú¨ÁöÑ RNN Êù•Á±ªÊØîÔºâÔºåÊâÄ‰ª•Âª∫ËÆÆÈòÖËØªÊú¨ÊñáÂâçÂØπÊúÄÂü∫Êú¨ÁöÑÂæ™ÁéØÁ•ûÁªèÁΩëÁªúÊúâ‰∏Ä‰∏™ÂàùÊ≠•ÁöÑ‰∫ÜËß£„ÄÇ</p>
<blockquote>
<p>ËøôÈÉ®ÂàÜÂÜÖÂÆπÊé®ËçêÈòÖËØª Ian Goodfellow Á≠â‰∫∫ÁºñÂÜôÁöÑ <em>Deep Learning</em> ‰∏Ä‰π¶‰∏≠ÁöÑ 10.1 ‰∏é 10.2 ËäÇ„ÄÇ</p>
</blockquote>
<h3 id="32-Âü∫‰∫éÁºñÁ†Å-Ëß£Á†Åencoder-decoderÁöÑÂ∫èÂàóÂà∞Â∫èÂàósequence2sequenceÊ®°Âûã">3.2. Âü∫‰∫éÁºñÁ†Å-Ëß£Á†ÅÔºàencoder-decoderÔºâÁöÑÂ∫èÂàóÂà∞Â∫èÂàóÔºàsequence2sequenceÔºâÊ®°Âûã</h3>
<p>Âú®‚æÉÁÑ∂ËØ≠‚æîÂ§ÑÁêÜÁöÑÂæàÂ§öÂ∫î‚Ω§‰∏≠ÔºåËæì‚ºäÂíåËæìÂá∫ÈÉΩÂèØ‰ª•ÊòØ‰∏çÂÆö‚ªìÂ∫èÂàó„ÄÇ‰ª•Êú∫Âô®ÁøªËØë‰∏∫‰æãÔºåËæì‚ºäÂèØ‰ª•ÊòØ‚ºÄÊÆµ‰∏çÂÆö‚ªìÁöÑËã±ËØ≠‚ΩÇÊú¨Â∫èÂàóÔºåËæìÂá∫ÂèØ‰ª•ÊòØ‚ºÄÊÆµ‰∏çÂÆö‚ªìÁöÑÊ≥ïËØ≠‚ΩÇÊú¨Â∫èÂàóÔºåÂΩìËæì‚ºäÂíåËæìÂá∫ÈÉΩÊòØ‰∏çÂÆö‚ªìÂ∫èÂàóÊó∂ÔºåÊàë‰ª¨ÂèØ‰ª•‰Ωø‚Ω§ÁºñÁ†ÅÂô®‚ÄîËß£Á†ÅÂô®Ôºàencoder-decoderÔºâÊû∂ÊûÑÊàñËÄÖsequence2sequenceÊ®°Âûã„ÄÇ</p>
<blockquote>
<p>ËøôÈÉ®ÂàÜÂÜÖÂÆπÊé®ËçêÈòÖËØª Ian Goodfellow Á≠â‰∫∫ÁºñÂÜôÁöÑ <em>Deep Learning</em> ‰∏Ä‰π¶‰∏≠ÁöÑ 10.4 ËäÇ„ÄÇ</p>
</blockquote>
<h3 id="33-Ê≥®ÊÑèÂäõÊú∫Âà∂">3.3. Ê≥®ÊÑèÂäõÊú∫Âà∂</h3>
<p>Transformer ÁöÑÊ†∏ÂøÉÊÄùÊÉ≥‚Äî‚ÄîËá™Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåÂÆûÈôÖ‰∏äÊòØÂèóÂêØÂèë‰∫éÊ≥®ÊÑèÂäõÊú∫Âà∂„ÄÇÂØπÊØîÊ≥®ÊÑèÂäõÊú∫Âà∂ÂíåËá™Ê≥®ÊÑèÂäõÊú∫Âà∂ÁöÑÂºÇÂêåÔºåÂèØ‰ª•Êõ¥Âä†ÁöÑÊ∑±ÂàªÁêÜËß£Ëá™Ê≥®ÊÑèÂäõÊú∫Âà∂ÁöÑ‰ΩúÁî®Êú∫ÁêÜ„ÄÇ</p>
<p>Âº∫ÁÉàÊé®ËçêÈòÖËØª <a class="link" href="https://zhuanlan.zhihu.com/p/37601161"  target="_blank" rel="noopener"
    >Âº†‰øäÊûó - Ê∑±Â∫¶Â≠¶‰π†‰∏≠ÁöÑÊ≥®ÊÑèÂäõÊ®°Âûã</a>„ÄÇ</p>
<p>ÂØπËã±ËØ≠ÊúâËá™‰ø°ÁöÑÂêåÂ≠¶ÂèØ‰ª•ÈòÖËØª <a class="link" href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/"  target="_blank" rel="noopener"
    >Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)</a>ÔºåÂÖ∂‰∏≠ÂåÖÂê´Â§ßÈáèÁöÑÂä®ÁîªÂÆû‰æã„ÄÇ</p>
<h3 id="34-ËØçÂµåÂÖ•word-embedding">3.4. ËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâ</h3>
<p>Êé®ËçêÈòÖËØªÊ≠§ÊñáÁ´† <a class="link" href="https://zhuanlan.zhihu.com/p/49271699"  target="_blank" rel="noopener"
    >Âº†‰øäÊûó - ‰ªéWord EmbeddingÂà∞BertÊ®°Âûã‚ÄîËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ‰∏≠ÁöÑÈ¢ÑËÆ≠ÁªÉÊäÄÊúØÂèëÂ±ïÂè≤</a> ÁöÑ<strong>ÂâçÂçäÈÉ®ÂàÜÂØπ Word Embedding ÁöÑ‰ªãÁªç</strong>„ÄÇ</p>
<h2 id="4-ÂàùÊé¢-transformer">4. ÂàùÊé¢ Transformer</h2>
<p>Transformer ÊòØÂü∫‰∫éËá™Ê≥®ÊÑèÂäõÊú∫Âà∂ÁöÑÂÖ®Êñ∞ encoder-decoder Ê®°Âûã„ÄÇÁõ∏ËæÉ‰∫é‰º†ÁªüÂæ™ÁéØÁ•ûÁªèÁΩëÁªúÊê≠Âª∫ÁöÑÂêåÁ±ªÊ®°ÂûãÔºåTransformer ÂÖ∑ÊúâÂ§öÈáç‰ºòÂäøÔºöËß£ÂÜ≥ÈïøÊúü‰æùËµñÁöÑÈóÆÈ¢òÔºåÂèØ‰ª•Âπ∂Ë°åÂåñÁ≠âÁ≠â„ÄÇ</p>
<p>Áé∞Âú®Êàë‰ª¨Â∑≤ÁªèÁü•ÈÅì‰∫Ü‰∏Ä‰∏™ encoder-decoder ÂèØ‰ª•ÂÆåÊàêÂ§öÁßçËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ‰ªªÂä°„ÄÇ‰∏∫‰∫Ü‰∏æ‰æãÊñπ‰æøÔºåÂÅáËÆæË¶ÅÂÆåÊàê‰∏Ä‰∏™Êú∫Âô®ÁøªËØë‰ªªÂä°Ôºö‰ªéÊ≥ïËØ≠ÁøªËØëÂà∞Ëã±ËØ≠„ÄÇTransformer ÂÅöÁöÑ‰∫ãÊÉÖÂ∞±ÊòØËøôÊ†∑ÁöÑÔºö</p>
<p><img src="/p/transformer-from-zero-1/attachments/the_transformer.png"
	width="1127"
	height="294"
	srcset="/p/transformer-from-zero-1/attachments/the_transformer_hu9dc15172e42e840ef18a078a4efb196f_44824_480x0_resize_box_3.png 480w, /p/transformer-from-zero-1/attachments/the_transformer_hu9dc15172e42e840ef18a078a4efb196f_44824_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="Transformer1"
	
	
		class="gallery-image" 
		data-flex-grow="383"
		data-flex-basis="920px"
	
></p>
<p>‰Ωú‰∏∫‰∏Ä‰∏™ encoder-decoder Ê®°ÂûãÔºåTransformer Â∞Ü‰ºöË¢´ÂàÜ‰∏∫ÁºñÁ†ÅÂô®ÔºàÂ∑¶‰æßÊµÖÁªøËâ≤ÔºâÂíåËß£Á†ÅÂô®ÔºàÂè≥‰æßÁ≤âËâ≤Ôºâ‰∏§ÈÉ®ÂàÜÔºö</p>
<p><img src="/p/transformer-from-zero-1/attachments/The_transformer_encoders_decoders.png"
	width="756"
	height="474"
	srcset="/p/transformer-from-zero-1/attachments/The_transformer_encoders_decoders_hu719cc4d57de2ce621a8aa9369922f3d4_39199_480x0_resize_box_3.png 480w, /p/transformer-from-zero-1/attachments/The_transformer_encoders_decoders_hu719cc4d57de2ce621a8aa9369922f3d4_39199_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="Transformer-enc-dec"
	
	
		class="gallery-image" 
		data-flex-grow="159"
		data-flex-basis="382px"
	
></p>
<p>Â¶Ç‰ΩïËÆæËÆ°Ëøô‰∏§‰∏™ÈÉ®ÂàÜÂë¢Ôºü<a class="link" href="https://arxiv.org/abs/1706.03762"  target="_blank" rel="noopener"
    >ËÆ∫Êñá</a>‰∏≠ÁöÑÂõæÁ§∫ÊòØËøôÊ†∑ÁöÑÔºö</p>
<p><img src="/p/transformer-from-zero-1/attachments/the_transformer2.png"
	width="668"
	height="832"
	srcset="/p/transformer-from-zero-1/attachments/the_transformer2_hue8ba12dbaf71f19d9d68468ec3964ba8_98723_480x0_resize_box_3.png 480w, /p/transformer-from-zero-1/attachments/the_transformer2_hue8ba12dbaf71f19d9d68468ec3964ba8_98723_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="Transformer2"
	
	
		class="gallery-image" 
		data-flex-grow="80"
		data-flex-basis="192px"
	
></p>
<p>Ëøô‰∏ÄÂº†ÂõæÊé©Áõñ‰∫ÜËÆ∏Â§öÁªÜËäÇÔºåÂ§ßÈáèÁöÑÁÆ≠Â§¥‰πü‰Ωø‰∫∫‰∏çÊòéÂ∞±Èáå„ÄÇÊöÇÊó∂Êù•ÁúãÔºåÊàë‰ª¨ÂèØ‰ª•ÂæóÂà∞‰ª•‰∏ã‰ø°ÊÅØÔºö</p>
<ol>
<li>Ëß£Á†ÅÂô®ÂíåÁºñÁ†ÅÂô®ÁöÑÁªìÊûÑÁ±ª‰ººÔºåÈÉΩÊòØÂ§öÂ§¥Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºàÂõæ‰∏≠ Multi-Head Attention ÂùóÔºåÊòØÂØπ‰∫éËá™Ê≥®ÊÑèÂäõÊú∫Âà∂ÁöÑÂèòÂåñ‰ΩøÁî®ÔºâÂíåÂâçÈ¶àÁ•ûÁªèÁΩëÁªúÔºàFeed ForwardÔºâÁöÑÂ†ÜÂè†Â§öÂ±Ç„ÄÇ</li>
<li>ËæìÂÖ•‰∏ç‰ªÖ‰ªÖÊòØÂè•Â≠êÁöÑËØçÂµåÂÖ•Ë°®Á§∫ÔºåËøòÈ¢ùÂ§ñÂ¢ûÂä†‰∫ÜÁß∞‰Ωú‰ΩçÁΩÆÁºñÁ†ÅÔºàPositional EncodingÔºâÁöÑÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ</li>
</ol>
<p>ÂÖ∂‰ªñÂßë‰∏îÊåâ‰∏ã‰∏çË°®„ÄÇ</p>
<h2 id="5-Âü∫Á°ÄÁÆóÊ≥ïÂíåÊ®°Âùó">5. Âü∫Á°ÄÁÆóÊ≥ïÂíåÊ®°Âùó</h2>
<h3 id="51-‰ΩçÁΩÆÁºñÁ†Åpositional-encoding">5.1. ‰ΩçÁΩÆÁºñÁ†ÅÔºàPositional encodingÔºâ</h3>
<p>‰∏Ä‰∏™‰º†ÁªüÁöÑÔºå‰ΩøÁî® RNN ÊûÑÂª∫ÁöÑ Encoder-Decoder Ê®°ÂûãÂØπ‰∫éËæìÂÖ•Âè•Â≠ê‰∏≠ÁöÑÂçïËØçÊòØÈÄê‰∏™ËØªÂèñÁöÑÔºöËØªÂèñÂÆåÂâç‰∏Ä‰∏™ÂçïËØçÔºåÊõ¥Êñ∞Ê®°ÂûãÁöÑÁä∂ÊÄÅÔºåÁÑ∂ÂêéÂú®Ê≠§Áä∂ÊÄÅ‰∏ãÂÜçËØªÂèñ‰∏ã‰∏Ä‰∏™ÂçïËØç„ÄÇËøôÁßçÊñπÂºèÂ§©ÁÑ∂ÁöÑÂåÖÂê´‰∫ÜÂè•Â≠êÁöÑ‰ΩçÁΩÆÂâçÂêéÂÖ≥Á≥ª„ÄÇ</p>
<p>Êàë‰ª¨ÂêéÈù¢‰ºöÂèëÁé∞ Transformer ÂØπ‰∫éËæìÂÖ•Âç¥Âπ∂ÈùûÈÄê‰∏™ËØªÂèñÔºåËÄåÊòØÂØπÊï¥‰∏™Âè•Â≠êÁöÑÊØè‰∏™ÂçïËØçËøõË°åÂêåÊó∂ËØªÂèñ„ÄÇËøôÁßçÊñπÂºèÂ∞±ÊòæÁÑ∂‰∏¢Â§±‰∫ÜÂè•Â≠êÁöÑÂâçÂêé‰ΩçÁΩÆÂÖ≥Á≥ª„ÄÇ</p>
<p>‰∏∫‰∫ÜËÉΩÂ§ü‰øùÁïôÂè•Â≠ê‰∏≠ÂçïËØçÂíåÂçïËØç‰πãÈó¥ÁöÑ‰ΩçÁΩÆÂÖ≥Á≥ªÔºåÈúÄË¶ÅÂ∞Ü‰ΩçÁΩÆ‰πüËûçÂêàËøõÂÖ•ËæìÂÖ•ÁöÑÂè•Â≠ê‰∏≠ÔºåÈúÄË¶ÅÂØπ‰ΩçÁΩÆËøõË°åÁºñÁ†Å„ÄÇ</p>
<p>Transformer ‰ΩøÁî®ÁöÑ‰ΩçÁΩÆÁºñÁ†ÅÁÆóÊ≥ïÂ¶Ç‰∏ãÂÆö‰πâÔºö</p>
<p>$$P E_{(p o s, 2 i)}=\sin \left(\text {pos} / 10000^{2 i / d_{\text {model}}}\right)$$</p>
<p>$$P E_{(p o s, 2 i+1)}=\cos \left(\text {pos} / 10000^{2 i / d_{\text {matel}}}\right)$$</p>
<p>Áî±ÂÖ¨ÂºèÊù•ÁúãÔºåÂØπ‰∫é‰∏Ä‰∏™Âè•Â≠êÔºåÊ≠§ÁºñÁ†ÅÁÆóÊ≥ïÂØπ‰∫éÂÅ∂Êï∞‰ΩçÁΩÆ  <code>2i</code> ÂíåÂ•áÊï∞‰ΩçÁΩÆ <code>2i + 1</code> ÂàÜÂºÄËøõË°åÁºñÁ†Å„ÄÇÁºñÁ†ÅÁöÑÁªìÊûúÊòØÊØè‰∏™‰ΩçÁΩÆÊúÄÁªàËΩ¨Âåñ‰∏∫ <code>d_model</code> Áª¥Â∫¶ÁöÑÂêëÈáè„ÄÇ</p>
<p>‰∏Ä‰∏™ÂØπ50‰∏™‰ΩçÁΩÆÁºñÁ†ÅËá≥ 512 Áª¥Â∫¶‰ΩçÁΩÆÂêëÈáèÁöÑÂõæÁ§∫‰æãÂ≠êÂ¶Ç‰∏ãÔºàÂÖ∂‰ΩúÁî®‰∫éÁöÑËæìÂÖ•Â∞±ÊòØÂè•Â≠êÔºåÂè•Â≠êÈïøËá≥ 50 ÂçïËØçÔºå‰∏îÊØè‰∏™ËØçÂµåÂÖ•ÁöÑÁª¥Â∫¶‰∏∫ 512ÔºâÔºö</p>
<p><img src="/p/transformer-from-zero-1/attachments/pos_enc.png"
	width="632"
	height="470"
	srcset="/p/transformer-from-zero-1/attachments/pos_enc_hu6898a0dedddced8a3d6450c5f57265e0_52743_480x0_resize_box_3.png 480w, /p/transformer-from-zero-1/attachments/pos_enc_hu6898a0dedddced8a3d6450c5f57265e0_52743_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="pos_enc"
	
	
		class="gallery-image" 
		data-flex-grow="134"
		data-flex-basis="322px"
	
></p>
<p>Ëøô‰∏™‰ΩçÁΩÆÂêëÈáè‰ºöÁõ¥Êé•Âä†Âú®ËØçÂµåÂÖ•‰∏ä‰ΩøÁî®Ôºå‰ªéËÄå‰ΩøËØçÂµåÂÖ•Âú®Âê´‰πâËøúËøëÁöÑË°®Á§∫ËÉΩÂäõ‰πãÂ§ñÂ¢ûÂä†‰∫ÜÂè•Â≠ê‰∏≠ÁöÑ‰ΩçÁΩÆÂÖ≥Á≥ªÁöÑË°®Á§∫ËÉΩÂäõÔºö</p>
<blockquote>
<p>‰ΩçÁΩÆÁºñÁ†ÅÂêëÈáèË¢´Âä†Âà∞ÂµåÂÖ•ÔºàembeddingÔºâÂêëÈáè‰∏≠„ÄÇÂµåÂÖ•Ë°®Á§∫‰∏Ä‰∏™ d Áª¥Á©∫Èó¥ÁöÑÊ†áËÆ∞ÔºåÂú® d Áª¥Á©∫Èó¥‰∏≠ÊúâÁùÄÁõ∏‰ººÂê´‰πâÁöÑÊ†áËÆ∞‰ºöÁ¶ªÂΩºÊ≠§Êõ¥Ëøë„ÄÇ‰ΩÜÊòØÔºåÂµåÂÖ•Âπ∂Ê≤°ÊúâÂØπÂú®‰∏ÄÂè•ËØù‰∏≠ÁöÑËØçÁöÑÁõ∏ÂØπ‰ΩçÁΩÆËøõË°åÁºñÁ†Å„ÄÇÂõ†Ê≠§ÔºåÂΩìÂä†‰∏ä‰ΩçÁΩÆÁºñÁ†ÅÂêéÔºåËØçÂ∞ÜÂü∫‰∫éÂÆÉ‰ª¨Âê´‰πâÁöÑÁõ∏‰ººÂ∫¶‰ª•ÂèäÂÆÉ‰ª¨Âú®Âè•Â≠ê‰∏≠ÁöÑ‰ΩçÁΩÆÔºåÂú® d Áª¥Á©∫Èó¥‰∏≠Á¶ªÂΩºÊ≠§Êõ¥Ëøë„ÄÇ</p>
</blockquote>
<p>ÊâçÁñèÂ≠¶ÊµÖÔºåÊ≤°Ê≥ï‰∏Ä‰∏™Áõ¥ËßÇÁöÑËßíÂ∫¶Êù•Ëß£Èáä‰∏∫‰ΩïËøôÊ†∑ËÆæËÆ°ÁºñÁ†Å‰ª•Âèä‰∏∫‰ΩïËøôÊ†∑ÁºñÁ†ÅÂèØ‰ª•Ëµ∑Âà∞ËøôÊ†∑ÁöÑÊïàÊûú„ÄÇËØ∑ÂêÑ‰ΩçÊåáÊïô„ÄÇ</p>
<p>ËÄÉËôëÊ≠§ÂáΩÊï∞ÈúÄË¶ÅÊúâÂ§ßÈáèÁöÑÂàáÁâáËµãÂÄºÊìç‰ΩúÔºàtensorflow api ÂÆûÁé∞Ëµ∑Êù•ËæÉ‰∏∫Âõ∞ÈöæÔºåÈúÄË¶ÅË∞ÉÁî®<code>assign</code>Êù•ÂÆûÁé∞numpyÁöÑËµãÂÄºËøêÁÆóÁ¨¶<code>=</code>ÔºâÔºåÊâÄ‰ª•‰ΩøÁî®numpyÁöÑapiÊù•ÂÆûÁé∞ÔºåÊúÄÂêé‰ΩøÁî®<code>tf.cast</code>Â∞ÜÂÖ∂Ëá™Âä®ËΩ¨Êç¢‰∏∫tensorÔºàÊ≠§Â§Ñ‰∏∫‰∏Ä‰∏™<code>eager tensor</code>Ôºâ„ÄÇ</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_angles</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">d_model</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="n">angle_rates</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span><span class="o">//</span><span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">d_model</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">pos</span> <span class="o">*</span> <span class="n">angle_rates</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">positional_encoding</span><span class="p">(</span><span class="n">position</span><span class="p">,</span> <span class="n">d_model</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="n">angle_rads</span> <span class="o">=</span> <span class="n">get_angles</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">position</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                          <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">d_model</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:],</span>
</span></span><span class="line"><span class="cl">                          <span class="n">d_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="c1"># Â∞Ü sin Â∫îÁî®‰∫éÊï∞ÁªÑ‰∏≠ÁöÑÂÅ∂Êï∞Á¥¢ÂºïÔºàindicesÔºâÔºõ2i</span>
</span></span><span class="line"><span class="cl">  <span class="n">angle_rads</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angle_rads</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="c1"># Â∞Ü cos Â∫îÁî®‰∫éÊï∞ÁªÑ‰∏≠ÁöÑÂ•áÊï∞Á¥¢ÂºïÔºõ2i+1</span>
</span></span><span class="line"><span class="cl">  <span class="n">angle_rads</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">angle_rads</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">  <span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">angle_rads</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> 
</span></span><span class="line"><span class="cl">  <span class="c1"># Âú®ËøôÈáåÂ¢ûÂä†‰∫Ü‰∏Ä‰∏™Áª¥Â∫¶„ÄÇeg: (50, 512) -&gt; (1, 50, 512)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># ‰∏∫‰ªÄ‰πàË¶ÅÂ¢ûÂä†‰∏Ä‰∏™Áª¥Â∫¶Âë¢ÔºüÂõ†‰∏∫ËæìÂÖ•Âà∞ Transformer ÁöÑËæìÂÖ•ÈÄöÂ∏∏ÊòØÂ§ö‰∏™Âè•Â≠êÂ±ÇÂè†Êàê‰∏Ä‰∏™ÊâπÊ¨°„ÄÇ</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># Â¢ûÂä†‰∏Ä‰∏™Áª¥Â∫¶Â∞±ÂèØ‰ª•Âà©Áî®ÂπøÊí≠Êú∫Âà∂‰∏ÄÊ¨°Âä†Ê≥ïÂ∞Ü‰∏Ä‰∏™ÊâπÊ¨°ÁöÑÊØè‰∏™Âè•Â≠êÊ∑ªÂä†‰∏ä‰ΩçÁΩÆÁºñÁ†Å„ÄÇ</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">pos_encoding</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="52-Ê≥®ÊÑèÂäõÊú∫Âà∂">5.2. Ê≥®ÊÑèÂäõÊú∫Âà∂</h3>
<p>ÂáÜÁ°ÆÊù•ËØ¥ÔºåÊòØÊåâÊØîÁº©ÊîæÁöÑÁÇπÁßØÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºàScaled dot product attentionÔºâ„ÄÇ</p>
<p>È°æÂêçÊÄù‰πâÔºåTransformer ‰∏ÄÁßçÁÇπÁßØÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºåÂπ∂‰∏îÂú®ÊôÆÈÄöÁöÑÁÇπÁßØÊ≥®ÊÑèÂäõÊú∫Âà∂‰∏äÂ¢ûÂä†‰∫Ü‚ÄúÊåâÊØîÁº©Êîæ‚ÄùËøô‰∏™ÁâπÊÄß„ÄÇ</p>
<p>Ê†πÊçÆËæìÂÖ•ÁöÑ‰∏çÂêåÔºåËøô‰∏™Ê®°ÂùóÊó¢ÂèØ‰ª•ÊòØËá™Ê≥®ÊÑèÂäõÔºå‰πüÂèØ‰ª•ÊòØÈùûËá™Ê≥®ÊÑèÂäõ„ÄÇ</p>
<p>Â¶ÇÊûúÂ∑≤ÁªèÈòÖËØª‰∫ÜÊú¨ÊñáÁ¨¨‰∏âÈÉ®ÂàÜÊé®ËçêÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂Áõ∏ÂÖ≥ÁöÑÊñáÁ´†<a class="link" href="https://zhuanlan.zhihu.com/p/37601161"  target="_blank" rel="noopener"
    >Âº†‰øäÊûó - Ê∑±Â∫¶Â≠¶‰π†‰∏≠ÁöÑÊ≥®ÊÑèÂäõÊ®°Âûã</a>ÔºåÂ∫îËØ•Â∑≤ÁªèÁêÜËß£‰∫ÜÊ≥®ÊÑèÂäõÊú∫Âà∂ÁöÑÊú¨Ë¥®Ôºö</p>
<p>ÂØπ‰∫é‰∏â‰∏™ËæìÂÖ•Ôºö</p>
<ul>
<li>QÔºöËØ∑Ê±Ç query</li>
<li>KÔºö‰∏ªÈîÆ key</li>
<li>VÔºöÊï∞ÂÄº value</li>
</ul>
<p>Ê≥®ÊÑèÂäõÊú∫Âà∂Êú¨Ë¥®Â∞±ÊòØ‰ΩøÁî® Q Âíå K Êù•ËÆ°ÁÆóÂá∫‚ÄúÊ≥®ÊÑèÂäõÊùÉÈáç‚ÄúÔºåÁÑ∂ÂêéÂà©Áî®Ê≥®ÊÑèÂäõÊùÉÈáçÂØπÔº∂ËøõË°åÂä†ÊùÉÊ±ÇÂíå„ÄÇ</p>
<p>ÊåâÊØîÁº©ÊîæÁöÑÁÇπÁßØÊ≥®ÊÑèÂäõÂÆö‰πâÂ¶Ç‰∏ãÔºö</p>
<p>$$
\text {Attention }(Q, K, V)=\operatorname{softmax}<em>{k}\left(\frac{Q K^{T}}{\sqrt{d</em>{k}}}\right) V
$$</p>
<p>‰ΩøÁî®ËÆ°ÁÆóÂõæÊù•Ë°®Á§∫Â¶Ç‰∏ãÔºö</p>
<p><img src="/p/transformer-from-zero-1/attachments/attention1.png"
	width="432"
	height="434"
	srcset="/p/transformer-from-zero-1/attachments/attention1_hu5394e8fadf02ddbdf64c8199f417f577_20855_480x0_resize_box_3.png 480w, /p/transformer-from-zero-1/attachments/attention1_hu5394e8fadf02ddbdf64c8199f417f577_20855_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="attention1"
	
	
		class="gallery-image" 
		data-flex-grow="99"
		data-flex-basis="238px"
	
></p>
<p>ÂèØ‰ª•ÁúãÂá∫ÔºåÊ≥®ÊÑèÂäõÊùÉÈáçÊòØÈÄöËøá Q Âíå K Áõ¥Êé•ËøõË°åÁÇπÁßØ<code>MatMul</code>ÔºåÂπ∂ÊåâÊØîÁº©Êîæ<code>Scale</code>ÔºàÈô§‰ª•Ê∑±Â∫¶ÁöÑÂπ≥ÊñπÊ†πÔºâÔºåÁÑ∂ÂêéËøõË°å softmax ÂæóÂà∞ÁöÑ„ÄÇ</p>
<p>ÂêåÊ†∑ÁöÑÔºå‰ΩøÁî®Ê≥®ÊÑèÂäõÊùÉÈáç‰πò‰∏ä V ‰æøÂæóÂà∞‰∫Ü‰∏ÄÊ¨°ËæìÂá∫„ÄÇ</p>
<p>Êúâ‰∏§ÁÇπÈúÄË¶ÅËÆ®ËÆ∫Ôºö</p>
<ol>
<li>‰∏∫‰ªÄ‰πàË¶ÅÊåâÊØîÁº©Êîæ<code>Scale</code>ÔºöËøôÊòØÂéüËÆ∫Êñá‰∏≠ÁöÑ‰∏Ä‰∏™Êé®Êµã‚Äî‚ÄîÂ¶ÇÊûúËæìÂÖ•ÁöÑQÔºåKÁª¥Â∫¶ËøáÂ§ßÔºåÂàô‰ºöÂØºËá¥ÁÇπÁßØÂêéÁöÑÁªìÊûúÂæàÂ§ßsoftmaxÂáΩÊï∞Êúâ‰∏Ä‰∏™ÁâπÁÇπÔºåÂΩìËæìÂÖ•ÁöÑ x Ë∂äÂ§ßÔºåÂÖ∂Ê¢ØÂ∫¶‰ºöË∂ãËøë‰∫é 0„ÄÇËøôÂØπ‰∫éÂü∫‰∫éÊ¢ØÂ∫¶‰∏ãÈôçÊ≥ïÁöÑ‰ºòÂåñÈùûÂ∏∏‰∏çÂà©„ÄÇÔºàËøô‰∏™ÊòØ‰∏Ä‰∏™ÊúâÊ†πÊçÆÁöÑÊé®ÊµãÔºöÂÅáËÆæqÂíåkÈÉΩÊòØÁã¨Á´ãÁöÑÈöèÊú∫ÂèòÈáèÔºåÈÇ£‰πàq ‰πò‰∏ä k ÊòØÂùáÂÄºÁöÑ 0 ÊñπÂ∑Æ‰∏∫ $d_k$ ÁöÑ„ÄÇÈô§‰ª•Ê∑±Â∫¶ÁöÑÂπ≥ÊñπÊ†πÔºåÂèØ‰ª•ËÆ©ÊñπÂ∑Æ‰∏∫ 1Ôºâ</li>
<li>Âú® softmax ÂâçÔºå‰∏∫‰ªÄ‰πàÊúâ‰∏Ä‰∏™ÂèØÈÄâÁöÑ <code>Mask</code> ËøáÁ®ãÔºö ËøôÊòØÁî±‰∫éÂú®Êï¥‰∏™Ê®°ÂûãÁöÑËøêË°åËøáÁ®ã‰∏≠ÔºåÂèØËÉΩÊ†πÊçÆËÆæËÆ°ÔºåË¶ÅÂøΩÁï•Êéâ‰∏Ä‰∫õËæìÂÖ•„ÄÇÂÖ≥‰∫éMaskÁöÑÁîüÊàêÔºåÂ∞ÜÂú®‰∏ã‰∏ÄÈÉ®ÂàÜËØ¶ÁªÜËß£Èáä„ÄÇÂÖ≥‰∫éMaskÁöÑ‰ΩøÁî®ÔºåÂ∞ÜÂú®#TODOÊó∂ÊèêÂèä„ÄÇ</li>
</ol>
<h4 id="521-ËÆ°ÁÆóÊ≠•È™§ÁªÜËäÇ">5.2.1. ËÆ°ÁÆóÊ≠•È™§ÁªÜËäÇ</h4>
<blockquote>
<p>Ê≥®ÊÑèÔºöËøô‰∏™‰æãÂ≠êÂíåÂÆûÈôÖ Transformer ‰ΩøÁî®ÁöÑÂÆûÈôÖËæìÂÖ•‰∏çÂêåÔºàÂπ∂ÈùûÁõ¥Êé•‰ΩøÁî®ËØçÂµåÂÖ•Êù•‰Ωú‰∏∫Query„ÄÅKeyÁ≠âËæìÂÖ•ÔºâÔºå‰ªÖ‰∏∫‰∫ÜËÉΩÂ§üÁî®Ëá™ÁÑ∂ËØ≠Ë®ÄÈòêËø∞ËÄåËÆæËÆ°„ÄÇÁ≤æÁ°ÆÁöÑËß£ÈáäÊàë‰ª¨ÊîæÂú®ÂêéÊñá„ÄÇ</p>
</blockquote>
<p>ÂÅáËÆæ Query Â∫èÂàóÊòØ‰∏Ä‰∏™Âè•Â≠êÔºåÈïøÂ∫¶‰∏∫ <code>seq_len_q</code>„ÄÇ</p>
<p>ËÄå Key Â∫èÂàó‰πüÊòØ‰∏Ä‰∫õ‰∏Ä‰∏™Âè•Â≠êÔºåÈïøÂ∫¶‰∏∫ <code>seq_len_k</code>„ÄÇ</p>
<p>Value Â∫èÂàó‰∏≠ÁöÑÊØè‰∏™ÂÄºÈÉΩÂØπÂ∫î Key Âè•Â≠ê‰∏≠ÁöÑ‰∏Ä‰∏™ÂçïËØçÔºåÊâÄ‰ª• v ÁöÑÈïøÂ∫¶<code>seq_len_v</code> Á≠â‰∫é <code>seq_len_k</code> „ÄÇ</p>
<p>Ê†πÊçÆ‰∏äÊñáÊèèËø∞ÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂ÁöÑËÆ°ÁÆóÊñπÊ≥ïÔºö‰æùÊ¨°Âèñ Query ‰∏≠ÁöÑÂçïËØçÔºåÊù•Âíå Key ‰∏≠ÁöÑ <code>seq_len_v</code> ‰∏™ÂçïËØç‰∏Ä‰∏ÄËÆ°ÁÆóÊ≥®ÊÑèÂäõÊùÉÈáçÔºåÂæóÂà∞ <code>seq_len_v</code> ‰∏™Ê≥®ÊÑèÂäõÊùÉÈáçÔºå‰ΩøÁî®Ëøô‰∏™ÊùÉÈáçÂØπ <code>seq_len_k</code> ÔºàÂÜçÊ¨°Âº∫Ë∞ÉÔºåÈïøÂ∫¶ÂøÖÈ°ªÁõ∏ÂêåÔºåËøôÈÉ®ÂàÜÊèèËø∞ÂØπÂ∫îÁùÄ‰∏ãÈù¢‰ª£Á†ÅÊ≥®Èáä‰∏≠ÁöÑË¶ÅÊ±Ç<code>2.</code>Ôºâ‰∏™ Value ËøõË°åÂä†ÊùÉÊ±ÇÂíåÔºåÂæóÂà∞‰∏Ä‰∏™ËæìÂá∫„ÄÇ</p>
<p>‰∏Ä‰∏™ Query Â∫èÂàóÂ∞Ü‰∫ßÁîü <code>seq_len_q</code> ‰∏™Âä†ÊùÉÊ±ÇÂíå„ÄÇ</p>
<p>ËÆ©Êàë‰ª¨Áî®Áü©ÈòµÁÇπ‰πòÁöÑÊ®°ÂºèÊù•ÊèèËø∞Ëøô‰∏™ËøáÁ®ãÔºö</p>
<p>ÂÅáËÆæÊØè‰∏™ÂçïËØçÁöÑÂµåÂÖ•‰∏∫<code>depth</code>Áª¥Â∫¶ÔºåÊòæÁÑ∂Ëøô‰∏™Ê≠•È™§ÊòØ:</p>
<p>Q Áü©Èòµ<code>(seq_len_q, depth)</code> Âíå K Áü©Èòµ<code>(seq_len_k, depth)</code> ÁöÑ<strong>ËΩ¨ÁΩÆ</strong>ÁöÑÁü©Èòµ‰πòÊ≥ï„ÄÇ</p>
<p>ÊúÄÁªàÂæóÂà∞Ê≥®ÊÑèÂäõÊùÉÈáç <code>(seq_len_q, seq_len_k)</code> Áü©Èòµ„ÄÇËøô‰∏™Áü©Èòµ‰πò‰∏ä Value Áü©Èòµ<code>(seq_len_v, depth_v)</code> ‰æøÊòØÂä†ÊùÉÊ±ÇÂíåËøáÁ®ãÔºåÊúÄÁªàÂæóÂà∞‰∫ÜËæìÂá∫Output <code>(seq_len_q, depth_v)</code>„ÄÇ</p>
<blockquote>
<p><code>depth_v</code> Ë°®Á§∫ Value Â∫èÂàó‰∏≠ÊØè‰∏™ÂÄºÁöÑÁª¥Â∫¶ÔºåÊòæÁÑ∂ÔºåËøô‰∏™Áª¥Â∫¶‰∏ç‰∏ÄÂÆöË¶ÅÂíå‰∏äÊñáÁöÑ<code>depth</code>‰∏ÄËá¥</p>
</blockquote>
<h4 id="522-‰ΩøÁî®ÂêëÈáèÂåñÊù•ÊèêÂçáÊïàÁéá">5.2.2. ‰ΩøÁî®ÂêëÈáèÂåñÊù•ÊèêÂçáÊïàÁéá</h4>
<p>ÊØè‰∏™ Query Â∫èÂàóÂØπÂ∫îÁùÄ‰∏Ä‰∏™ Key Â∫èÂàóÔºå‰ΩÜËøô Query-Key ÁªÑÂêàÂΩºÊ≠§‰πãÈó¥ÊòØÁã¨Á´ãÁöÑ„ÄÇÂÆåÂÖ®ÂèØ‰ª•Â∞Ü Query„ÄÅKey„ÄÅValue Â†ÜÂè†ÊàêÊâπÔºå‰∏ÄÊ¨°ËøêÁÆóÊêûÂÆö„ÄÇ<strong>Áü©Èòµ‰πòÊ≥ïÊàñÊòØËΩ¨ÁΩÆÊòØÈíàÂØπÊúÄÂêéÁöÑ‰∏§‰∏™Áª¥Â∫¶</strong>ÔºåÊâÄ‰ª•Âè™ÈúÄË¶Å‰øùÊåÅÂâçÁΩÆÁª¥Â∫¶ÂåπÈÖçÔºàÂØπÂ∫îÔºå‰∏ãÊñπÊ≥®ÈáäÁöÑË¶ÅÊ±Ç<code>1.</code>ÔºâÔºåËÆ°ÁÆóÁªìÊûúÂíå‰∏äÈù¢ÂÆåÂÖ®Á≠âÊïà„ÄÇ</p>
<p>‰∏æ‰∏™‰æãÂ≠êÔºöËã•Êúâ <code>batch_size</code> ÊâπÊ¨°ÔºåÊØèÊâπÊ¨° <code>N</code> Êù°ÁöÑ QueryÔºåKey„ÄÇ ÂÖ∂ËÆ°ÁÆóÂÆåÂÖ®ÂèØ‰ª•ÁªÑÁªáÊàê <code>(batch_size, N, seq_len_q, depth)</code>ÁÇπ‰πò<code>(batch_size, N, seq_len_q, depth)</code>ÁöÑËΩ¨ÁΩÆÔºåÊúÄÁªàÂæóÂà∞<code>(batch_size, N, seq_len_q, seq_len_k)</code> ÂΩ¢Áä∂ÁöÑÂº†Èáè„ÄÇ</p>
<p>mask ‰ª•‰πò‰ª•‰∏Ä‰∏™ÊûÅÂ§ßÁöÑË¥üÊï∞<code>-1e9</code>ÔºåÁÑ∂ÂêéÂú®Âä†‰∏äÊ≥®ÊÑèÂäõÊùÉÈáçÔºåÊúÄÁªàËææÂà∞‰Ωø‰∏Ä‰∫õ‰ΩçÁΩÆÁöÑ Value Â§±ÊïàÁöÑÊïàÊûú„ÄÇÂè™ÈúÄË¶Å‰øùËØÅÂÖ∂ÂèØÈÄöËøáÂπøÊí≠Êú∫Âà∂ËÉΩÂ§üËá™Âä®ËΩ¨Êç¢‰∏∫ <code>(..., seq_len_q, seq_len_k)</code> ÂΩ¢Áä∂Ôºà‰ª£Á†ÅÊ≥®Èáä‰∏≠ÁöÑË¶ÅÊ±Ç<code>3.</code>)„ÄÇ</p>
<blockquote>
<p>Ëøô‰∏ÄË¶ÅÊ±ÇÂ∞Ü‰ºöÂΩ±Âìç‰∏ã‰∏ÄËäÇÁöÑÈÅÆÊå°ÔºàMaskingÔºâÁöÑÂÆûÁé∞„ÄÇ</p>
</blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">scaled_dot_product_attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;&#34;&#34; ËøôÈÉ®ÂàÜÊòØÂØπ‰∫éËæìÂÖ•ÁöÑÂº†ÈáèÁª¥Â∫¶ËøõË°åÊèèËø∞
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">  1. q, k, v ÂøÖÈ°ªÂÖ∑ÊúâÂåπÈÖçÁöÑÂâçÁΩÆÁª¥Â∫¶„ÄÇ
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">  2. k, v ÂøÖÈ°ªÊúâÂåπÈÖçÁöÑÂÄíÊï∞Á¨¨‰∫å‰∏™Áª¥Â∫¶Ôºå‰æãÂ¶ÇÔºöseq_len_k = seq_len_v„ÄÇ
</span></span></span><span class="line"><span class="cl"><span class="s2">  
</span></span></span><span class="line"><span class="cl"><span class="s2">  3. ËôΩÁÑ∂ mask Ê†πÊçÆÂÖ∂Á±ªÂûãÔºàÂ°´ÂÖÖÊàñÂâçÁûªÔºâÊúâ‰∏çÂêåÁöÑÂΩ¢Áä∂Ôºå‰ΩÜÊòØ mask ÂøÖÈ°ªËÉΩËøõË°åÂπøÊí≠ËΩ¨Êç¢‰ª•‰æøÊ±ÇÂíå„ÄÇ
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">  
</span></span></span><span class="line"><span class="cl"><span class="s2">  ÂèÇÊï∞:
</span></span></span><span class="line"><span class="cl"><span class="s2">    q: ËØ∑Ê±ÇÁöÑÂΩ¢Áä∂ == (..., seq_len_q, depth)
</span></span></span><span class="line"><span class="cl"><span class="s2">    k: ‰∏ªÈîÆÁöÑÂΩ¢Áä∂ == (..., seq_len_k, depth)
</span></span></span><span class="line"><span class="cl"><span class="s2">    v: Êï∞ÂÄºÁöÑÂΩ¢Áä∂ == (..., seq_len_v, depth_v)
</span></span></span><span class="line"><span class="cl"><span class="s2">    mask: Float Âº†ÈáèÔºåÂÖ∂ÂΩ¢Áä∂ËÉΩËΩ¨Êç¢Êàê
</span></span></span><span class="line"><span class="cl"><span class="s2">          (..., seq_len_q, seq_len_k)„ÄÇÈªòËÆ§‰∏∫None„ÄÇ
</span></span></span><span class="line"><span class="cl"><span class="s2">    
</span></span></span><span class="line"><span class="cl"><span class="s2">  ËøîÂõûÂÄº:
</span></span></span><span class="line"><span class="cl"><span class="s2">    ËæìÂá∫ÔºåÊ≥®ÊÑèÂäõÊùÉÈáç
</span></span></span><span class="line"><span class="cl"><span class="s2">  &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">matmul_qk</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># ÂæóÂà∞Âº†ÈáèÂΩ¢Áä∂‰∏∫ (..., seq_len_q, seq_len_k)</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">    <span class="c1"># Áº©Êîæ matmul_qk</span>
</span></span><span class="line"><span class="cl">  <span class="n">dk</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">k</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># dk Âç≥ depth</span>
</span></span><span class="line"><span class="cl">  <span class="n">scaled_attention_logits</span> <span class="o">=</span> <span class="n">matmul_qk</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dk</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Â∞Ü mask Âä†ÂÖ•Âà∞Áº©ÊîæÁöÑÂº†Èáè‰∏ä„ÄÇ</span>
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">scaled_attention_logits</span> <span class="o">+=</span> <span class="p">(</span><span class="n">mask</span> <span class="o">*</span> <span class="o">-</span><span class="mf">1e9</span><span class="p">)</span>  
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># softmax Âú®ÊúÄÂêé‰∏Ä‰∏™ËΩ¥Ôºàseq_len_kÔºâ‰∏äÂΩí‰∏ÄÂåñÔºåÂõ†Ê≠§ÂàÜÊï∞</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Áõ∏Âä†Á≠â‰∫é1„ÄÇ</span>
</span></span><span class="line"><span class="cl">  <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scaled_attention_logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (..., seq_len_q, seq_len_k)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>  <span class="c1"># (..., seq_len_q, depth_v)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">attention_weights</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="523-Â¶Ç‰Ωï‰Ωú‰∏∫Ëá™Ê≥®ÊÑèÂäõ‰ΩøÁî®">5.2.3. Â¶Ç‰Ωï‰Ωú‰∏∫Ëá™Ê≥®ÊÑèÂäõ‰ΩøÁî®</h4>
<p>Êúâ‰∫∫‰ºöËøôÊ†∑ÊÄªÁªìÔºöËá™Ê≥®ÊÑèÂäõÂ∞±ÊòØÂ∞ÜÂêå‰∏Ä‰∏™Âè•Â≠êÂêåÊó∂‰Ωú‰∏∫ Query Âíå Key Êù•‰ΩøÁî®„ÄÇÊàëËÆ§‰∏∫Ëøò‰∏çÂ§üÁ≤æÁ°Æ„ÄÇ</p>
<p>‰∫ãÂÆû‰∏äÔºåËæìÂÖ•Ëá™Ê≥®ÊÑèÂäõÁöÑ Query„ÄÅKey Âíå Value ÈÉΩÊù•Ëá™ÂéüÂßãÂµåÂÖ•ÁöÑÁ∫øÊÄßÂèòÊç¢ÔºöÂàõÂª∫‰∏â‰∏™‰ºöÈöèÁùÄÊ®°ÂûãËÆ≠ÁªÉËøáÁ®ã‰∏çÊñ≠‰ºòÂåñÁöÑÁü©Èòµ$W^Q$Ôºå$W^K$ Âíå $W^V$ÔºåÂéüÂßãËØçÂµåÂÖ•‰πò‰∏ä‰∏â‰∏™Áü©Èòµ‰ªéËÄåÂæóÂà∞ÁúüÊ≠£ÁöÑ Query„ÄÅKey Âíå ValueÔºà‰πüÂèØ‰ª•ÁêÜËß£‰∏∫‰∏â‰∏™Áã¨Á´ãÁöÑÂÖ®ËøûÊé•Á•ûÁªèÁΩëÁªúÔºåËæìÂÖ•ËäÇÁÇπÊï∞Èáè‰∏∫ËØçÂµåÂÖ•ÁöÑÁª¥Â∫¶ÔºåËæìÂá∫ËäÇÁÇπÊï∞ÈáèÂàÜÂà´‰∏∫QueryÔºåKey Âíå Value ÁöÑÁª¥Â∫¶Ôºâ„ÄÇ</p>
<p>ÂÖ∂ËøáÁ®ãÂ¶Ç‰∏ãÔºö</p>
<p><img src="/p/transformer-from-zero-1/attachments/self_attention.png"
	width="875"
	height="552"
	srcset="/p/transformer-from-zero-1/attachments/self_attention_hua65c3e6c2024ce004bd25224487b57c1_38480_480x0_resize_box_3.png 480w, /p/transformer-from-zero-1/attachments/self_attention_hua65c3e6c2024ce004bd25224487b57c1_38480_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="self_attention"
	
	
		class="gallery-image" 
		data-flex-grow="158"
		data-flex-basis="380px"
	
></p>
<p>ÂÖ∂‰ΩôËøáÁ®ãÂàôÂÆåÂÖ®Âíå‰∏äËø∞ËøáÁ®ã‰∏ÄËá¥Ôºö</p>
<p><img src="/p/transformer-from-zero-1/attachments/self_attention2.png"
	width="786"
	height="747"
	srcset="/p/transformer-from-zero-1/attachments/self_attention2_hu87587cfd246d48e562a537c2833f60a8_61686_480x0_resize_box_3.png 480w, /p/transformer-from-zero-1/attachments/self_attention2_hu87587cfd246d48e562a537c2833f60a8_61686_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="self_attention2"
	
	
		class="gallery-image" 
		data-flex-grow="105"
		data-flex-basis="252px"
	
></p>
<p>ËÄåËá™Ê≥®ÊÑèÂäõÁöÑÊ≥®ÊÑèÊïàÊûú‰πüÊòØÈÄêÂ±ÇÂèòÂæóÈõÜ‰∏≠„ÄÇ‰ΩøÁî®ÂõæÂΩ¢ÂåñÊù•ÂØπËá™Ê≥®ÊÑèÂäõÁöÑÊïàÊûúËøõË°åÂàùÊ≠•ÁêÜËß£„ÄÇ</p>
<p>ÂΩìÂè™ÁªèËøáÁ∫øÊÄßÂèòÊç¢ÁöÑÊ≥®ÊÑèÂäõÊïàÊûúÔºö</p>
<p><img src="/p/transformer-from-zero-1/attachments/1-layer-sa.png"
	width="388"
	height="336"
	srcset="/p/transformer-from-zero-1/attachments/1-layer-sa_huaf0f73356d3a333cb09eb5b1d1d6905a_30160_480x0_resize_box_3.png 480w, /p/transformer-from-zero-1/attachments/1-layer-sa_huaf0f73356d3a333cb09eb5b1d1d6905a_30160_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="1-layer-sa"
	
	
		class="gallery-image" 
		data-flex-grow="115"
		data-flex-basis="277px"
	
></p>
<p>Ê≥®ÊÑèÂäõÊòæÁÑ∂ÈùûÂ∏∏ÂàÜÊï£ÔºåÊúâÁßçÊäì‰∏çÂà∞Ë¶ÅÈ¢ÜÁöÑÊÑüËßâ„ÄÇ</p>
<p>ËÄåÁªèËøá‰∫Ü5Â±ÇËá™Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåÂçï‰∏™ÂçïËØçÁöÑÊ≥®ÊÑèÂäõÂºÄÂßãÈõÜ‰∏≠‰∫éÂ∞ëÊï∞ÈÉ®ÂàÜ„ÄÇ</p>
<p><img src="/p/transformer-from-zero-1/attachments/fin-layer-sa.png"
	width="362"
	height="338"
	srcset="/p/transformer-from-zero-1/attachments/fin-layer-sa_hua725f0b59172e6a24314a8cb50dfbd10_25050_480x0_resize_box_3.png 480w, /p/transformer-from-zero-1/attachments/fin-layer-sa_hua725f0b59172e6a24314a8cb50dfbd10_25050_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="fin-layer-sa"
	
	
		class="gallery-image" 
		data-flex-grow="107"
		data-flex-basis="257px"
	
></p>
<h3 id="53-ÈÅÆÊå°-mask">5.3. ÈÅÆÊå° Mask</h3>
<h4 id="531-Â°´ÂÖÖÈÅÆÊå°">5.3.1. Â°´ÂÖÖÈÅÆÊå°</h4>
<p>Â¶ÇÊûú‰∏Ä‰∏™ËæìÂÖ•Âè•Â≠êÁî±‰∫éÈïøÁü≠‰∏ç‰∏Ä‰∏çÊñπ‰æøËÆ°ÁÆóÊàñÊòØÂÖ∂‰ªñÂéüÂõ†ÈúÄË¶ÅË°•ÂÖÖ‰∏Ä‰∫õÂ°´ÂÖÖÊ†áËÆ∞Ôºàpad tokensÔºâÔºåÊòæÁÑ∂Âú®ËæìÂá∫ÁªìÊûúÁöÑÊó∂ÂÄôÂ∫îËØ•ÊääËøô‰∫õÊó†ÊÑè‰πâÁöÑÂ°´ÂÖÖÊ†áËÆ∞ÊéíÈô§ÔºåÂõ†Ê≠§ÈúÄË¶Å‰∏Ä‰∏™ÂáΩÊï∞‰∫ßÁîüÊ≠§Áî®ÈÄîÁöÑ mask„ÄÇ</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">create_padding_mask</span><span class="p">(</span><span class="n">seq</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1"># ÂØπ‰∫é‰∏Ä‰∏™Â∫èÂàóÔºåÂ¶ÇÊûúÊüê‰ΩçÁΩÆÂÖ∂ÂÄº‰∏∫0ÔºåÂàôËÆ§ÂÆö‰∏∫Â°´ÂÖÖÊ†áËÆ∞ÔºåÂú®Ê≠§‰ΩçÁΩÆÊ†á 1</span>
</span></span><span class="line"><span class="cl">  <span class="n">seq</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">seq</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="c1"># ‰∏∫‰∫ÜËÉΩÂ§üÂà©Áî®ÂπøÊí≠Êú∫Âà∂ÂåπÈÖçÊ≥®ÊÑèÂäõÊùÉÈáçÂº†ÈáèÔºåÈúÄË¶ÅÂ¢ûÂä†ÂøÖË¶ÅÁöÑÁª¥Â∫¶</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">seq</span><span class="p">[:,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># (batch_size, 1, 1, seq_len)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>ÊµãËØïÊïàÊûúÔºö</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">create_padding_mask</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">&lt;tf.Tensor: id=207703, shape=(3, 1, 1, 5), dtype=float32, numpy=
</span></span></span><span class="line"><span class="cl"><span class="s2">array([[[[0., 0., 1., 1., 0.]]],
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">       [[[0., 0., 0., 1., 1.]]],
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">       [[[1., 1., 1., 0., 0.]]]], dtype=float32)&gt;
</span></span></span><span class="line"><span class="cl"><span class="s2">&#34;&#34;&#34;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="532-ÂâçÁûªÈÅÆÊå°look-ahead-mask">5.3.2. ÂâçÁûªÈÅÆÊå°Ôºàlook-ahead maskÔºâ</h4>
<p>ÂâçÁûªÈÅÆÊå°ÈÄöÂ∏∏Áî®‰∫éÈúÄË¶ÅÂè™ËÄÉËôëÂ∫èÂàó‰∏≠ÁöÑÂâç‰∏ÄÈÉ®ÂàÜÁöÑÊó∂ÂÄôÔºåËøô‰∏™ÈÅÆÊå°Â∞Ü‰ºöÁî®Âú® Transform ÁöÑËß£Á†ÅÂô®ÈÉ®ÂàÜÔºåÂÖ∂ËÆæËÆ°ÂéüÁêÜÊòØÈ¢ÑÊµã‰∏Ä‰∏™ÂçïËØçÂè™ËÄÉËôëÊ≠§ÂçïËØçÂâçÁöÑÂçïËØçÔºåËÄå‰∏çËÄÉËôëÊ≠§ÂçïËØçÂêéÁöÑÈÉ®ÂàÜ„ÄÇ</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">create_look_ahead_mask</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># tf.linalg.band_path(Tensor, -1, 0) ÊòØÂèñTensorÁöÑÂ∑¶‰∏ãÂçäÁü©Èòµ</span>
</span></span><span class="line"><span class="cl">  <span class="n">mask</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">band_part</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">)),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">mask</span>  <span class="c1"># (seq_len, seq_len)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>ÊúÄÁªàÊïàÊûúÂæóÂà∞Ôºö</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">temp</span> <span class="o">=</span> <span class="n">create_look_ahead_mask</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">temp</span>
</span></span><span class="line"><span class="cl"><span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">&lt;tf.Tensor: id=207718, shape=(3, 3), dtype=float32, numpy=
</span></span></span><span class="line"><span class="cl"><span class="s2">array([[0., 1., 1.],
</span></span></span><span class="line"><span class="cl"><span class="s2">       [0., 0., 1.],
</span></span></span><span class="line"><span class="cl"><span class="s2">       [0., 0., 0.]], dtype=float32)&gt;
</span></span></span><span class="line"><span class="cl"><span class="s2">&#34;&#34;&#34;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="54-Â§öÂ§¥Ê≥®ÊÑèÂäõmulti-head-attention">5.4. Â§öÂ§¥Ê≥®ÊÑèÂäõÔºàMulti-head attentionÔºâ</h3>
<p><img src="/p/transformer-from-zero-1/attachments/mul_attention1.png"
	width="438"
	height="447"
	srcset="/p/transformer-from-zero-1/attachments/mul_attention1_hu406f1dbbcd280550648486a6640892d9_36586_480x0_resize_box_3.png 480w, /p/transformer-from-zero-1/attachments/mul_attention1_hu406f1dbbcd280550648486a6640892d9_36586_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="mul_attention1"
	
	
		class="gallery-image" 
		data-flex-grow="97"
		data-flex-basis="235px"
	
></p>
<p>ÂâçÊñáËØ¥Âà∞Ôºå‰ΩøÁî®‰∏ÄÁªÑ‰ºöÈöèÁùÄÊ®°ÂûãËÆ≠ÁªÉËøáÁ®ã‰∏çÊñ≠‰ºòÂåñÁöÑÁü©Èòµ$W^Q$Ôºå$W^K$ Âíå $W^V$ÔºåÂèØ‰ª•ÈÄöËøáÂØπËØçÂµåÂÖ• X ÊàñËÄÖÂâç‰∏ÄÂ±ÇÁöÑËæìÂá∫ R Áõ∏‰πòËÄåÂæóÂà∞‰∏ÄÂ•óÂèØ‰ª•ËæìÂÖ•ËøõÊ≥®ÊÑèÂäõÊú∫Âà∂ÁöÑ Query, Key Âíå Value„ÄÇ</p>
<p>Â§öÂ§¥Ê≥®ÊÑèÂäõÊú∫Âà∂ÊòØÂ∞ÜÂàùÂßãÁöÑËØçÂêëÈáèÔºàÁ¨¨‰∏ÄÂ±ÇÔºâÊàñÂâç‰∏ÄÂ±ÇÁöÑËæìÂÖ•ÔºàÁ¨¨‰∫åÂ±ÇÂºÄÂßãÔºâÈÄöËøáÁ∫øÊÄßÂèòÊç¢ËΩ¨Êç¢‰∏∫Â§öÁªÑ  Query, Key Âíå ValueÔºå‰ªéËÄåÂæóÂà∞‰∏çÂêåÁöÑËæìÂá∫ Z„ÄÇÊúÄÂêéÂ∞ÜÊâÄÊúâÁöÑËæìÂá∫ÊãºÂêàËµ∑Êù•ÔºåÈÄöËøáÂèØËÆ≠ÁªÉÁöÑÁ∫øÊÄßÂèòÊç¢ $W^O$ ËûçÂêà‰∏∫‰∏Ä‰∏™ËæìÂá∫Ôºö</p>
<p><img src="/p/transformer-from-zero-1/attachments/mul_attention2.png"
	width="1436"
	height="804"
	srcset="/p/transformer-from-zero-1/attachments/mul_attention2_hua474a07e32ad4c44bf3c82d3f49b46fc_166831_480x0_resize_box_3.png 480w, /p/transformer-from-zero-1/attachments/mul_attention2_hua474a07e32ad4c44bf3c82d3f49b46fc_166831_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="mul_attention1"
	
	
		class="gallery-image" 
		data-flex-grow="178"
		data-flex-basis="428px"
	
></p>
<p>‰ªéÊ≥®ÊÑèÂäõËßíÂ∫¶ÁúãÔºåÁî±‰∫éÁü©ÈòµÊòØÈöèÊú∫ÂàùÂßãÂåñÁöÑÔºåÈöèÁùÄËÆ≠ÁªÉÁöÑËøáÁ®ãÔºåÊúÄÁªà‰∏çÂêåÁöÑQuery, KeyÂèØËÉΩÂæóÂà∞‰∏çÂêåÁöÑÊ≥®ÊÑèÂäõÁªìÊûú„ÄÇ</p>
<p><img src="/p/transformer-from-zero-1/attachments/fin-layer-sa.png"
	width="362"
	height="338"
	srcset="/p/transformer-from-zero-1/attachments/fin-layer-sa_hua725f0b59172e6a24314a8cb50dfbd10_25050_480x0_resize_box_3.png 480w, /p/transformer-from-zero-1/attachments/fin-layer-sa_hua725f0b59172e6a24314a8cb50dfbd10_25050_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="fin-layer-sa"
	
	
		class="gallery-image" 
		data-flex-grow="107"
		data-flex-basis="257px"
	
></p>
<p><img src="/p/transformer-from-zero-1/attachments/fin-layer-sa2.png"
	width="390"
	height="341"
	srcset="/p/transformer-from-zero-1/attachments/fin-layer-sa2_hu177c48548b6b1d8d327c668807a2464a_28347_480x0_resize_box_3.png 480w, /p/transformer-from-zero-1/attachments/fin-layer-sa2_hu177c48548b6b1d8d327c668807a2464a_28347_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="fin-layer-sa"
	
	
		class="gallery-image" 
		data-flex-grow="114"
		data-flex-basis="274px"
	
></p>
<p>ËÆ∫ÊñáËÆ§‰∏∫Ôºö</p>
<ul>
<li>ËøôÁßçÊñπÂºèÊãìÂ±ï‰∫ÜÊ®°Âûã‰∏ìÊ≥®‰∫é‰∏çÂêå‰ΩçÁΩÆÁöÑËÉΩÂäõ„ÄÇ</li>
<li>Ê®°ÂûãÊúÄÁªàÁöÑ‚ÄúÊ≥®ÊÑèÂäõ‚ÄùÂÆûÈôÖ‰∏äÊòØÊù•Ëá™‰∏çÂêå‚ÄúË°®Á§∫Â≠êÁ©∫Èó¥‚ÄùÁöÑÊ≥®ÊÑèÂäõÁöÑÁªºÂêà„ÄÇ</li>
</ul>
<p>ÂÅö‰∏™ÊØîÂñªÊù•ËØ¥ÔºåËøôÂ∞±Â•ΩÂÉèÊòØÂÖ´‰∏™Êúâ‰∏çÂêåÈòÖËØª‰π†ÊÉØÁöÑÁøªËØëÂÆ∂‰∏ÄÂêåÁøªËØëÂêå‰∏Ä‰∏™Âè•Â≠êÔºå‰ªñ‰ª¨ÊØè‰∏™‰∫∫ÂèØËÉΩÁøªËØëÊó∂ÈòÖËØªÈ°∫Â∫èÂíåÂÖ≥Ê≥®ÁÇπÈÉΩÊúâÊâÄ‰∏çÂêåÔºåÁªºÂêà‰ªñ‰ª¨ÂÖ´‰∏™‰∫∫ÁöÑÊÑèËßÅÔºåÊúÄÁªàÂæóÂá∫Êù•ÁöÑÁøªËØëÁªìÊûúÂèØËÉΩ‰ºöÊõ¥Âä†ÂáÜÁ°Æ„ÄÇ</p>
<p>ÈÄöËøáÁªßÊâø <code>tf.keras.layers.Layer</code> ÂèØ‰ª•ÂØπÂ§öÂ§¥Ê≥®ÊÑèÂäõÊú∫Âà∂ËøõË°åÁªìÊûÑÊ∏ÖÊô∞ÁöÑÂÆûÁé∞„ÄÇ</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    ÂèÇÊï∞: d_model ÂøÖÈ°ªËÉΩË¢´ num_heads Êï¥Èô§
</span></span></span><span class="line"><span class="cl"><span class="s2">    d_model: Áî±‰∫éË¶ÅÊò†Â∞Ñ num_heads ÁªÑ Q,K,V. d_model ÁöÑÂÄºÈúÄË¶Å‰∏∫ num_heads * depth
</span></span></span><span class="line"><span class="cl"><span class="s2">    num_heads: ‰ª£Ë°®Ê≥®ÊÑèÂäõÊú∫Âà∂ÁöÑÂ§¥Êï∞
</span></span></span><span class="line"><span class="cl"><span class="s2">  &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="nb">super</span><span class="p">(</span><span class="n">MultiHeadAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">assert</span> <span class="n">d_model</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">==</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">depth</span> <span class="o">=</span> <span class="n">d_model</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">wq</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">wk</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">wv</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="nf">split_heads</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;ÂàÜÊãÜÊúÄÂêé‰∏Ä‰∏™Áª¥Â∫¶Âà∞ (num_heads, depth).
</span></span></span><span class="line"><span class="cl"><span class="s2">    ËΩ¨ÁΩÆÁªìÊûú‰ΩøÂæóÂΩ¢Áä∂‰∏∫ (batch_size, num_heads, seq_len, depth)
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">depth</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">q</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># ËøôÈáåÈááÂèñÂ∞Ü q,k,v ÂÖàÁ∫øÊÄßÂèòÊç¢Âà∞ (..., seq_len, d_model)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># ÂÜçÊãÜÂàÜÊàê num_heads ‰ªΩ (..., nums_heads, seq_ken, d_model / nums_heads)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># ËøôÂíåÁõ¥Êé•Â∞ÜÂéüÂßã q,k,v Á∫øÊÄßÂèòÊç¢Êàê nums_heads ÁªÑÊòØÁ≠âÊïàÁöÑÔºÅËøôÊ†∑ÂÜôÊïàÁéáÊõ¥È´òÔºÅ</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wq</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)</span>
</span></span><span class="line"><span class="cl">    <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wk</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)</span>
</span></span><span class="line"><span class="cl">    <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wv</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_heads</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># (batch_size, num_heads, seq_len_q, depth)</span>
</span></span><span class="line"><span class="cl">    <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_heads</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># (batch_size, num_heads, seq_len_k, depth)</span>
</span></span><span class="line"><span class="cl">    <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_heads</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># (batch_size, num_heads, seq_len_v, depth)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)</span>
</span></span><span class="line"><span class="cl">    <span class="n">scaled_attention</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">scaled_dot_product_attention</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="n">scaled_attention</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">scaled_attention</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>  <span class="c1"># (batch_size, seq_len_q, num_heads, depth)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">concat_attention</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">scaled_attention</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                  <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">))</span>  <span class="c1"># (batch_size, seq_len_q, d_model)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">concat_attention</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len_q, d_model)</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">attention_weights</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="541-‰ª£Á†ÅÂàÜÊûê">5.4.1. ‰ª£Á†ÅÂàÜÊûê</h4>
<p>Áî±‰∫éÁª¥Â∫¶Â§öÔºå‰∏§Â§ÑÊõ¥Êîπ<code>reshape</code> ÂíåËΩ¨ÁΩÆÊìç‰Ωú<code>transpose</code>‰ª§‰∫∫Â§¥ÁßÉ„ÄÇÊâÄ‰ª•Êù•ËØ¶ÁªÜËÆ≤Ëß£‰∏Ä‰∏ãTensorÊòØÂ¶Ç‰ΩïÂú®Â§öÂ§¥Ê≥®ÊÑèÂäõÊú∫Âà∂ÂäõÊµÅÂä®ÁöÑ„ÄÇÂ¶ÇÊûúÂØπÊ®°ÂûãÂÆûÁé∞ÊâãÂà∞ÊìíÊù•ÁöÑÁöÑÂêåÂ≠¶ÂèØ‰ª•Áõ¥Êé•Ë∑≥ËøáÔºö</p>
<p>È¶ñÂÖàÔºåÊàë‰ª¨Á°ÆÂÆöË¶ÅËæìÈÄÅÁªôÊ≥®ÊÑèÂäõÊú∫Âà∂ <code>scaled_dot_product_attention</code> ÁöÑÂΩ¢Áä∂ÊòØ <code>(batch_size, nums_heads, seq_len_q, depth)</code>ÔºåÈÄö‰øóÊù•ËÆ≤ÔºåÊ≥®ÊÑèÂäõÊú∫Âà∂ÂáΩÊï∞Â∞Ü‰ºöÂπ∂Ë°åÂ§ÑÁêÜ <code>batch_size</code> ÊâπÂè•Â≠êÔºåÊØèÊâπÂè•Â≠ê <code>nums_heads</code> Âè•„ÄÇ‰∏∫‰∫ÜÂæóÂà∞ÂêàÈÄÇÁöÑËæìÂá∫ÔºåË¶ÅÈÄöËøá‰ª•‰∏ãÂá†Ê≠•Ôºö</p>
<ol>
<li>Â∞ÜËæìÂÖ•Êò†Â∞ÑËá≥Ë∂≥Â§üÁª¥Â∫¶<code>(batch_size, seq_len, input_depth) -&gt; (batch_size, seq_len, d_model)</code></li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="o">...</span>
</span></span><span class="line"><span class="cl">    <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wq</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)</span>
</span></span><span class="line"><span class="cl">    <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wk</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)</span>
</span></span><span class="line"><span class="cl">    <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wv</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)</span>
</span></span><span class="line"><span class="cl"><span class="o">...</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Ëøô‰∏™ <code>d_model</code> ÁöÑÊ∑±Â∫¶ÊòæÁÑ∂Â§ß‰∫éÊàë‰ª¨ÈúÄË¶ÅÁöÑ <code>depth</code>ÔºåËøôÊòØ‰∏∫‰∫Ü‰∏ã‰∏ÄÊ≠•ÊãÜÊàê <code>num_heads</code>ÔºåÂ∞ÜÂ§öÊ¨°Á∫øÊÄßÂèòÊç¢ÔºåËΩ¨Êç¢‰∏∫‰∏ÄÊ¨°„ÄÇ</p>
<ol start="2">
<li>Â∞ÜËæìÂÖ•ÊãÜÂàÜ‰∏∫Â§öÂ§¥</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl">  <span class="k">def</span> <span class="nf">split_heads</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;ÂàÜÊãÜÊúÄÂêé‰∏Ä‰∏™Áª¥Â∫¶Âà∞ (num_heads, depth).
</span></span></span><span class="line"><span class="cl"><span class="s2">    ËΩ¨ÁΩÆÁªìÊûú‰ΩøÂæóÂΩ¢Áä∂‰∏∫ (batch_size, num_heads, seq_len, depth)
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">depth</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="o">...</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># ËøôÈáåËÆ∞ÂæóË¶ÅÊää batch_size ‰º†ËøõÂéª</span>
</span></span><span class="line"><span class="cl">    <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_heads</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># (batch_size, num_heads, seq_len_q, depth)</span>
</span></span><span class="line"><span class="cl">    <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_heads</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># (batch_size, num_heads, seq_len_k, depth)</span>
</span></span><span class="line"><span class="cl">    <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_heads</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># (batch_size, num_heads, seq_len_v, depth)</span>
</span></span><span class="line"><span class="cl"><span class="o">...</span>
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>ÂàÜÊãÜÊúÄÂêé‰∏Ä‰∏™Áª¥Â∫¶Âà∞ (num_heads, depth)</p>
</blockquote>
<p>ÂêëÈáèËßíÂ∫¶ËÄåË®ÄÔºö <code>reshape</code> Êìç‰ΩúÂ∞ÜÂº†Èáè‰∏≠ÊØè‰∏ÄË°å <code>d_model</code> ÈÉΩÊãÜÊàê‰∫Ü <code>num_heads</code> ‰∏™ <code>depth</code> ÈïøÂ∫¶ÁöÑË°åÂêëÈáè„ÄÇÂç≥Ôºö<code>(batch_size, seq_len, d_model) -&gt; (batch_size, seq_len, nums_heads, depth)</code>„ÄÇ</p>
<p>‰ªéÁ•ûÁªèÁΩëÁªúËßíÂ∫¶ËÄåË®ÄÔºöÁî±‰∫éÂØπ‰∫éÂçïÂ±ÇÂÖ®ËøûÊé•ÁΩëÁªúÔºåËæìÂÖ•Â±Ç‰∏é<strong>ÈöêÂ±ÇËäÇÁÇπÁöÑ‰ªª‰Ωï‰∏Ä‰∏™Â≠êÈõÜ</strong>ÁªìÂêàÔºåÈÉΩÊòØ‰∏Ä‰∏™ÂÆåÊï¥ÁöÑÂçïÈöêÂ±ÇÂÖ®ËøûÊé•ÁΩëÁªú„ÄÇ‰πüÂ∞±ÊòØËØ¥ÔºåËøôÁßçÊãÜÂàÜÂÆåÂÖ®ÂèØ‰ª•ÁúãÂÅöÂ∞ÜÂâç‰∏ÄÊ≠•<code>input_depth</code> ‰∏™ËäÇÁÇπÂà∞ <code>d_model</code> ‰∏™ËäÇÁÇπÁöÑÂÖ®ËøûÊé•ÁΩëÁªúÔºåÊãÜÂàÜÊàê‰∫Ü <code>nums_heads</code> ‰∏™Â∞èÁöÑ <code>input_depth</code> ‰∏™ËäÇÁÇπÂà∞ <code>depth</code> ‰∏™ËäÇÁÇπÁöÑÂÖ®ËøûÊé•ÁΩëÁªú„ÄÇ</p>
<p>ÁÑ∂ÂêéÔºåÊàë‰ª¨Â§ÑÁêÜÁöÑ‰ªçÁÑ∂ÊòØÂ∫èÂàóÊú¨Ë∫´ÔºåÂõ†Ê≠§ÔºåÈÄöËøáËΩ¨ÁΩÆ <code>transpose</code> Â∞Ü <code>seq_len</code> ÊîæÂõûÂÆÉÂéüÊù•ÁöÑ‰ΩçÁΩÆÔºåËÆ© <code>nums_heads</code> Êàê‰∏∫‰∏Ä‰∏™ÂâçÁΩÆÁª¥Â∫¶Ôºö<code> (batch_size, seq_len, nums_heads, depth) -&gt; (batch_size, num_heads, seq_len, depth)</code></p>
<p>Ëá™Ê≥®ÊÑèÂäõÊú∫Âà∂ÁöÑËØ¶ÁªÜËøêÁÆóËøáÁ®ãÂ∑≤ÁªèÂú®ÂâçÊñáËØ¥ÁöÑÂæàÊ∏ÖÊ•ö‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØÂØπËæìÂá∫ÁöÑÂ§ÑÁêÜ„ÄÇ</p>
<ol start="3">
<li>Â∞ÜÂ§öÂ§¥ËæìÂá∫ÈÄöËøáÂÖ®ËøûÊé•Êò†Â∞Ñ‰∏∫‰∏Ä‰∏™ËæìÂá∫</li>
</ol>
<p>ÊòæÁÑ∂Ëá™Ê≥®ÊÑèÂäõÊú∫Âà∂ÂáΩÊï∞ÁöÑËæìÂá∫ÂΩ¢Áä∂Â∞ÜÊòØ<code>(batch_size, num_heads, seq_len_q, depth)</code>„ÄÇ</p>
<p>‰∏∫‰∫ÜËÉΩÂ§üÊñπ‰æøÂú∞Â∞ÜÂ§öÂ§¥ÁªìÊûúÊãºÂêàËµ∑Êù•ÔºåÈ¶ñÂÖàÊàë‰ª¨Â∞ÜÂÖ∂ËΩ¨ÁΩÆÂà∞ÂÄíÊï∞Á¨¨‰∫å‰∏™Áª¥Â∫¶„ÄÇ</p>
<p>ÁÑ∂ÂêéÔºå2.‰∏≠<strong>ÊÄé‰πàÊãÜÂºÄÁöÑÔºåÂ∞±ÊÄé‰πàÊãºÂõûÂéª</strong>„ÄÇ</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="o">...</span>
</span></span><span class="line"><span class="cl">    <span class="n">scaled_attention</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">scaled_attention</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>  <span class="c1"># (batch_size, seq_len_q, num_heads, depth)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">concat_attention</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">scaled_attention</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                  <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">))</span>  <span class="c1"># (batch_size, seq_len_q, d_model)</span>
</span></span><span class="line"><span class="cl"><span class="o">...</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>ÊúÄÂêéÔºåÈÄöËøáÂÖ®ËøûÊé•Â±ÇÂ∞ÜÊãºÂêàÂ•ΩÁöÑËæìÂá∫ËûçÂêàËµ∑Êù•Ôºö</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="o">...</span>
</span></span><span class="line"><span class="cl"><span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">concat_attention</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len_q, d_model)</span>
</span></span><span class="line"><span class="cl"><span class="o">...</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>ËøôÈáåÔºåÁªèËøáÂÖ®ËøûÊé•Â±ÇËûçÂêàÂêéÁöÑÊúÄÂêé‰∏ÄÁª¥‰ªçÁÑ∂ÊòØ <code>d_model</code>„ÄÇ</p>
<h3 id="55-ÁÇπÂºèÂâçÈ¶àÁΩëÁªúpoint-wise-feed-forward-network">5.5. ÁÇπÂºèÂâçÈ¶àÁΩëÁªúÔºàPoint wise feed forward networkÔºâ</h3>
<p>ÁÇπÂºèÂâçÈ¶àÁΩëÁªúÁî±‰∏§Â±ÇÂÖ®ËÅîÊé•Â±ÇÁªÑÊàêÔºå‰∏§Â±Ç‰πãÈó¥Êúâ‰∏Ä‰∏™ ReLU ÊøÄÊ¥ªÂáΩÊï∞„ÄÇ</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">point_wise_feed_forward_network</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dff</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">dff</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>  <span class="c1"># Á¨¨‰∏ÄÂ±ÇËæìÂá∫Â∞∫ÂØ∏ (batch_size, seq_len, dff)</span>
</span></span><span class="line"><span class="cl">      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>  <span class="c1"># Á¨¨‰∫åÂ±ÇËæìÂá∫Â∞∫ÂØ∏ (batch_size, seq_len, d_model)</span>
</span></span><span class="line"><span class="cl">  <span class="p">])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><code>dff</code>: ËßÑÂÆö‰∫ÜÁÇπÂºèÂâçÈ¶àÁ•ûÁªèÁΩëÁªúÁöÑÂÜÖÈÉ®<strong>Á¨¨‰∏ÄÂ±ÇËæìÂá∫ËäÇÁÇπ</strong>„ÄÇ</p>
<p>Âú®ËÆ∫Êñá‰∏≠ÔºåËøô‰∏™Á•ûÁªèÁΩëÁªúË¢´Áß∞‰Ωú<strong>‰ΩçÁΩÆÂºèÂâçÈ¶àÁ•ûÁªèÁΩëÁªú</strong>ÔºàPosition-wise Feed-Forward Networks
InÔºå‰∏çÁü•ÈÅì‰∏∫‰ªÄ‰πàTensorflowÁöÑÊñáÊ°£Ë¶ÅÊîπÂêçÔºâÔºåÂÖ∂ÂÆö‰πâÂ¶Ç‰∏ãÔºö</p>
<p>$$
\mathrm{FFN}(x)=\max \left(0, x W_{1}+b_{1}\right) W_{2}+b_{2}
$$</p>
<p>ÂèØ‰ª•ÁúãÂá∫ÂÖ∂Êú¨Ë¥®‰∏äÊòØ‰∏§Ê¨°Á∫øÊÄßÂèòÊç¢ÁöÑ‰∏≤ËÅîÔºà‰∏çËÄÉËôëÊøÄÊ¥ªÂáΩÊï∞ÁöÑÊÉÖÂÜµ‰∏ãÔºâ„ÄÇ</p>
<p>Êàë‰ª¨ËÄÉËôë‰∏Ä‰∏™<code>(..., seq_len, depth)</code> ÁöÑËæìÂÖ•ÔºåÁ¨¨‰∏ÄÊ¨°Á∫øÊÄßÂèòÊç¢Áõ∏ÂΩì‰∫éÈíàÂØπÊØè‰∏ÄË°åÔºàÊç¢Âè•ËØùËØ¥ÔºåÂè•Â≠êÁöÑÊØè‰∏™‰ΩçÁΩÆÔºâÔºåÂÅö‰∫Ü‰∏Ä‰∏™Áõ∏ÂêåÔºà‰ΩÜÈöêÂ±ÇÂèÇÊï∞‰∏çÂêåÔºâÁöÑÂÖ®ËøûÊé•ÁΩëÁªúÔºåËæìÂÖ•ËäÇÁÇπÊï∞ <code>depth</code> Âíå ËæìÂá∫ËäÇÁÇπÊï∞ <code>dff</code>„ÄÇÂæóÂà∞ <code>Ôºà..., seq_len, dff)</code>„ÄÇÂêåÁêÜÁ¨¨‰∫åÊ¨°Á∫øÊÄßÂèòÊç¢Á±ª‰ººÔºåÂæóÂà∞<code>(..., seq_len, d_model)</code>„ÄÇ</p>
<p>‰∫ãÂÆû‰∏äÔºåÂÆÉÂè™ÊòØ‰∏Ä‰∏™Â§öÂ±ÇÁ•ûÁªèÁΩëÁªúÔºå‰ΩÜËÄÉËôëÂÆÉÁ≠âÂêåÂú∞Â§ÑÁêÜÂè•Â≠êÁöÑÊØè‰∏™<strong>‰ΩçÁΩÆ</strong>ÔºåËµ∑ÂêçÂ¶ÇÊ≠§‰πüÁÆóÂêàÁêÜ„ÄÇ</p>
<h2 id="6-ÁºñÁ†ÅÂô®Ëß£Á†ÅÂô®">6. ÁºñÁ†ÅÂô®Ëß£Á†ÅÂô®</h2>
<p>Êúâ‰∫Ü‰∏äÈù¢ÁöÑËØ∏Â§öÊ®°ÂùóÔºåÁªà‰∫éÂèØ‰ª•Âè¨Âî§Ê≠§ÂõæÔºö</p>
<p><img src="/p/transformer-from-zero-1/attachments/the_transformer2.png"
	width="668"
	height="832"
	srcset="/p/transformer-from-zero-1/attachments/the_transformer2_hue8ba12dbaf71f19d9d68468ec3964ba8_98723_480x0_resize_box_3.png 480w, /p/transformer-from-zero-1/attachments/the_transformer2_hue8ba12dbaf71f19d9d68468ec3964ba8_98723_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="Transformer2"
	
	
		class="gallery-image" 
		data-flex-grow="80"
		data-flex-basis="192px"
	
></p>
<p>Â∑¶‰æßÁºñÁ†ÅÂô®ÔºåÂè≥‰æßËß£Á†ÅÂô®„ÄÇ</p>
<p>Âπ∂ÂºÄÂßãÁªÑË£ÖÁºñÁ†ÅÂô®ÂíåËß£Á†ÅÂô®Ôºö</p>
<blockquote>
<p>Transformer Ê®°Âûã‰∏éÊ†áÂáÜÁöÑÂÖ∑ÊúâÊ≥®ÊÑèÂäõÊú∫Âà∂ÁöÑÂ∫èÂàóÂà∞Â∫èÂàóÊ®°ÂûãÔºàsequence to sequence with attention modelÔºâÔºåÈÅµÂæ™Áõ∏ÂêåÁöÑ‰∏ÄËà¨Ê®°Âºè„ÄÇ</p>
<p>ËæìÂÖ•ËØ≠Âè•ÁªèËøá N ‰∏™ÁºñÁ†ÅÂô®Â±ÇÔºå‰∏∫Â∫èÂàó‰∏≠ÁöÑÊØè‰∏™ËØç/Ê†áËÆ∞ÁîüÊàê‰∏Ä‰∏™ËæìÂá∫„ÄÇ</p>
<p>Ëß£Á†ÅÂô®ÂÖ≥Ê≥®ÁºñÁ†ÅÂô®ÁöÑËæìÂá∫‰ª•ÂèäÂÆÉËá™Ë∫´ÁöÑËæìÂÖ•ÔºàËá™Ê≥®ÊÑèÂäõÔºâÊù•È¢ÑÊµã‰∏ã‰∏Ä‰∏™ËØç„ÄÇ</p>
</blockquote>
<p>‰ªéËøôÈáå‰∏ÄÁõ¥Âà∞Âà∞ Transformer ÁöÑÂÆåÊàêÔºåÊàë‰ª¨ÂßãÁªàÂøΩÁï• mask ÁöÑÂÆûÈôÖÁªÜËäÇ„ÄÇÁî±‰∫éËøô‰∏ÄÈÉ®ÂàÜÊ∂âÂèäÂà∞Ê®°ÂûãÁöÑËÆ≠ÁªÉ‰ºòÂåñÊâÄ‰ª•Êàë‰ª¨ÊîæÂú®‰∏ã‰∏ÄÁØáÊñáÁ´†Â±ïÂºÄÊù•ËÆ≤„ÄÇÂú®Ê≠§Êàë‰ª¨Âè™ÊääÂÆÉÂΩìÂÅö‰∏Ä‰∏™ÂèÇÊï∞Êö¥Èú≤ÁªôÂ§ñÈÉ®Ê®°Âùó„ÄÇÂπ∂‰º†ÁªôÂÜÖÈÉ®Ê®°Âùó„ÄÇ</p>
<h3 id="61-ÁºñÁ†ÅÂô®Â±Ç">6.1. ÁºñÁ†ÅÂô®Â±Ç</h3>
<p>ÂØπ‰∫éÁºñÁ†ÅÂô®Ôºå‰∏Ä‰∏™ÁºñÁ†ÅÂô®Â±ÇÊòØÂÖ∂Ê†∏ÂøÉÁöÑÊúÄÂ∞èÂçï‰Ωç„ÄÇ</p>
<p><img src="/p/transformer-from-zero-1/attachments/enc_sub.png"
	width="218"
	height="292"
	srcset="/p/transformer-from-zero-1/attachments/enc_sub_hu0058cf4ff73a16050fe814c62aff015e_20208_480x0_resize_box_3.png 480w, /p/transformer-from-zero-1/attachments/enc_sub_hu0058cf4ff73a16050fe814c62aff015e_20208_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="enc_sub"
	
	
		class="gallery-image" 
		data-flex-grow="74"
		data-flex-basis="179px"
	
></p>
<p>ÊØè‰∏™ÁºñÁ†ÅÂô®Â±ÇÂåÖÊã¨‰ª•‰∏ãÂ≠êÂ±ÇÔºö</p>
<ol>
<li>Â§öÂ§¥Ê≥®ÊÑèÂäõÔºàÊúâÂ°´ÂÖÖÈÅÆÊå°Ôºâ</li>
<li>ÁÇπÂºèÂâçÈ¶àÁΩëÁªúÔºàPoint wise feed forward networksÔºâ„ÄÇ</li>
</ol>
<p>ÊØè‰∏™Â≠êÂ±ÇÂú®ÂÖ∂Âë®Âõ¥Êúâ‰∏Ä‰∏™ÊÆãÂ∑ÆËøûÊé•ÔºàÂõæ‰∏≠ÊúÄÂ∑¶‰æßÁöÑ‰∏ä‰∏ã‰∏§‰∏™ÈªëÁÆ≠Â§¥ÔºâÔºåÁÑ∂ÂêéËøõË°åÂ±ÇÂΩí‰∏ÄÂåñ„ÄÇÊÆãÂ∑ÆËøûÊé•ÊúâÂä©‰∫éÈÅøÂÖçÊ∑±Â∫¶ÁΩëÁªú‰∏≠ÁöÑÊ¢ØÂ∫¶Ê∂àÂ§±ÈóÆÈ¢ò„ÄÇ</p>
<p>ÊØè‰∏™Â≠êÂ±ÇÁöÑËæìÂá∫ÊòØ <code>LayerNorm(x + Sublayer(x))</code>„ÄÇÂΩí‰∏ÄÂåñÊòØÂú® <code>d_model</code>ÔºàÊúÄÂêé‰∏Ä‰∏™ÔºâÁª¥Â∫¶ÂÆåÊàêÁöÑ„ÄÇTransformer ‰∏≠Êúâ N ‰∏™ÁºñÁ†ÅÂô®Â±Ç„ÄÇ</p>
<p>Ê≠§Â§ñÂØπ‰∫éÊØè‰∏™Â≠êÂ±ÇÁöÑËæìÂá∫ÔºåÈÉΩ‰ΩøÁî®‰∫Ü0.1Ê¶ÇÁéáÁöÑÁöÑ<code>dropout</code>„ÄÇ</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">EncoderLayer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="nb">super</span><span class="p">(</span><span class="n">EncoderLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">mha</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">point_wise_feed_forward_network</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dff</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">layernorm1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">layernorm2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span> <span class="c1"># Â°´ÂÖÖÈÅÆÊå°Â∞ÜÂú®Ë∞ÉÁî®Êó∂‰º†ÂÖ•</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">attn_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mha</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>  <span class="c1"># (batch_size, input_seq_len, d_model)</span>
</span></span><span class="line"><span class="cl">    <span class="n">attn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">attn_output</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">out1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layernorm1</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">attn_output</span><span class="p">)</span>  <span class="c1"># (batch_size, input_seq_len, d_model)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">out1</span><span class="p">)</span>  <span class="c1"># (batch_size, input_seq_len, d_model)</span>
</span></span><span class="line"><span class="cl">    <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">ffn_output</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">out2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layernorm2</span><span class="p">(</span><span class="n">out1</span> <span class="o">+</span> <span class="n">ffn_output</span><span class="p">)</span>  <span class="c1"># (batch_size, input_seq_len, d_model)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">out2</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="62-Ëß£Á†ÅÂô®Â±Ç">6.2. Ëß£Á†ÅÂô®Â±Ç</h3>
<p><img src="/p/transformer-from-zero-1/attachments/dec_sub.png"
	width="206"
	height="354"
	srcset="/p/transformer-from-zero-1/attachments/dec_sub_hue58f25544b2438c34520be540e4522b8_34928_480x0_resize_box_3.png 480w, /p/transformer-from-zero-1/attachments/dec_sub_hue58f25544b2438c34520be540e4522b8_34928_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="dec_sub"
	
	
		class="gallery-image" 
		data-flex-grow="58"
		data-flex-basis="139px"
	
></p>
<p>ÊØè‰∏™Ëß£Á†ÅÂô®Â±ÇÂåÖÊã¨‰ª•‰∏ãÂ≠êÂ±ÇÔºö</p>
<ol>
<li>ÈÅÆÊå°ÁöÑÂ§öÂ§¥Ê≥®ÊÑèÂäõÔºàÂâçÁûªÈÅÆÊå°ÂíåÂ°´ÂÖÖÈÅÆÊå°Ôºâ</li>
<li>Â§öÂ§¥Ê≥®ÊÑèÂäõÔºàÁî®Â°´ÂÖÖÈÅÆÊå°Ôºâ„ÄÇVÔºàÊï∞ÂÄºÔºâÂíå KÔºà‰∏ªÈîÆÔºâÊé•Êî∂ÁºñÁ†ÅÂô®ËæìÂá∫‰Ωú‰∏∫ËæìÂÖ•„ÄÇQÔºàËØ∑Ê±ÇÔºâÊé•Êî∂ÈÅÆÊå°ÁöÑÂ§öÂ§¥Ê≥®ÊÑèÂäõÂ≠êÂ±ÇÁöÑËæìÂá∫„ÄÇ</li>
<li>ÁÇπÂºèÂâçÈ¶àÁΩëÁªú
ÊØè‰∏™Â≠êÂ±ÇÂú®ÂÖ∂Âë®Âõ¥Êúâ‰∏Ä‰∏™ÊÆãÂ∑ÆËøûÊé•ÔºåÁÑ∂ÂêéËøõË°åÂ±ÇÂΩí‰∏ÄÂåñ„ÄÇÊØè‰∏™Â≠êÂ±ÇÁöÑËæìÂá∫ÊòØ <code>LayerNorm(x + Sublayer(x))</code>„ÄÇÂΩí‰∏ÄÂåñÊòØÂú® <code>d_model</code>ÔºàÊúÄÂêé‰∏Ä‰∏™ÔºâÁª¥Â∫¶ÂÆåÊàêÁöÑ„ÄÇ</li>
</ol>
<p>Transformer ‰∏≠ÂÖ±Êúâ N ‰∏™Ëß£Á†ÅÂô®Â±Ç„ÄÇ</p>
<p>ÂΩì Q Êé•Êî∂Âà∞Ëß£Á†ÅÂô®ÁöÑÁ¨¨‰∏Ä‰∏™Ê≥®ÊÑèÂäõÂùóÁöÑËæìÂá∫ÔºåÂπ∂‰∏î K Êé•Êî∂Âà∞ÁºñÁ†ÅÂô®ÁöÑËæìÂá∫Êó∂ÔºåÊ≥®ÊÑèÂäõÊùÉÈáçË°®Á§∫Ê†πÊçÆÁºñÁ†ÅÂô®ÁöÑËæìÂá∫Ëµã‰∫àËß£Á†ÅÂô®ËæìÂÖ•ÁöÑÈáçË¶ÅÊÄß„ÄÇÊç¢‰∏ÄÁßçËØ¥Ê≥ïÔºåËß£Á†ÅÂô®ÈÄöËøáÊü•ÁúãÁºñÁ†ÅÂô®ËæìÂá∫ÂíåÂØπÂÖ∂Ëá™Ë∫´ËæìÂá∫ÁöÑËá™Ê≥®ÊÑèÂäõÔºåÈ¢ÑÊµã‰∏ã‰∏Ä‰∏™ËØç„ÄÇ</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">DecoderLayer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="nb">super</span><span class="p">(</span><span class="n">DecoderLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">mha1</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">mha2</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">point_wise_feed_forward_network</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dff</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"> 
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">layernorm1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">layernorm2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">layernorm3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">dropout3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">           <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># enc_output.shape == (batch_size, input_seq_len, d_model)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">attn1</span><span class="p">,</span> <span class="n">attn_weights_block1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mha1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, d_model)</span>
</span></span><span class="line"><span class="cl">    <span class="n">attn1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">attn1</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">out1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layernorm1</span><span class="p">(</span><span class="n">attn1</span> <span class="o">+</span> <span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="n">attn2</span><span class="p">,</span> <span class="n">attn_weights_block2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mha2</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">enc_output</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">out1</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, d_model)</span>
</span></span><span class="line"><span class="cl">    <span class="n">attn2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">attn2</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">out2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layernorm2</span><span class="p">(</span><span class="n">attn2</span> <span class="o">+</span> <span class="n">out1</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, d_model)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">out2</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, d_model)</span>
</span></span><span class="line"><span class="cl">    <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout3</span><span class="p">(</span><span class="n">ffn_output</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">out3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layernorm3</span><span class="p">(</span><span class="n">ffn_output</span> <span class="o">+</span> <span class="n">out2</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, d_model)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">out3</span><span class="p">,</span> <span class="n">attn_weights_block1</span><span class="p">,</span> <span class="n">attn_weights_block2</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>ÊòæÁÑ∂ÔºåÁõ∏ËæÉ‰∫éÁºñÁ†ÅÂô®ÔºåÈô§‰∫ÜÁî®‰∫éËá™Ê≥®ÊÑèÂäõÁöÑÂ§öÂ§¥Ê≥®ÊÑèÂäõÂ±Ç„ÄÇËß£Á†ÅÂô®Â¢ûÂä†‰∫Ü‰∏ÄÂ±ÇÊ≥®ÊÑèÂäõÂ±ÇÁî®‰∫éÂÆûÁé∞ÁºñÁ†ÅÂô®ÂíåËß£Á†ÅÂô®‰πãÈó¥ÁöÑÊ≥®ÊÑèÂäõ„ÄÇÂÖ∂‰ªñ‰∏éÁºñÁ†ÅÂô®ÂÆåÂÖ®‰∏ÄËá¥„ÄÇ</p>
<p>Ê≥®ÊÑèÔºö‰∏§Â±ÇÊ≥®ÊÑèÂäõ‰ΩøÁî®ÁöÑÈÅÆÊå°Á±ªÂûãÁï•Êúâ‰∏çÂêåÔºÅ</p>
<h3 id="63-ÁºñÁ†ÅÂô®">6.3. ÁºñÁ†ÅÂô®</h3>
<p>Áî±‰∫éÂ∞ÅË£Ö‰∫Ü‰∏äÊñáÂÆûÁé∞ÁöÑÊâÄÊúâÊ®°Âùó„ÄÇÊâÄ‰ª•Ëøô‰∏™Ê®°ÂùóÁöÑÂèÇÊï∞ÊòæÂæóÊúâ‰∫õÂ§öÔºåÊàë‰ª¨Âè™ÂÖ≥Ê≥®Ê≠§Â±ÇÁâπÊúâÁöÑÂèÇÊï∞Ôºö</p>
<ul>
<li><code>num_layers</code>ÔºöËßÑÂÆöÁºñÁ†ÅÂô®‰ΩøÁî®Â§öÂ∞ë‰∏™ÁºñÁ†ÅÂô®Â±Ç„ÄÇ</li>
<li><code>input_vocab_size</code>: ÂéüËØ≠ÊñôÁöÑËØçÊ±áÈáè</li>
<li><code>maximum_position_encoding</code>ÔºöÊúÄÂ§ßÁöÑ‰ΩçÁΩÆÁºñÁ†ÅÔºå‰ª£Ë°®‰ΩçÁΩÆÁºñÁ†ÅÊúÄÈïøÂåπÈÖçÁöÑ‰ΩçÁΩÆÈïøÂ∫¶</li>
</ul>
<p>ÂÖ∂ÊÄª‰ΩìÊ≠•È™§ÂåÖÊã¨‰∏âÊ≠•Ôºö</p>
<ol>
<li>Â∞ÜÂéüÂßãÂè•Â≠êÂçïËØçÁºñÁ†ÅÊõ¥Êç¢‰∏∫ËØçÂµåÂÖ•</li>
<li>Â∞ÜËØçÂµåÂÖ•Âä†‰∏ä‰ΩçÁΩÆÁºñÁ†Å</li>
<li>Â∞ÜÂ§ÑÁêÜËøáÂêéÁöÑËæìÂá∫ËæìÂÖ•ËßÑÂÆöÂ•ΩÁöÑÂ§ö‰∏™ÁºñÁ†ÅÂô®Â±Ç</li>
</ol>
<p>ÂÖ∂‰∏≠ÔºöÂú®ÂéüÂßãÂè•Â≠êÁöÑËØçÂµåÂÖ•‰∏äÈúÄË¶Å‰πò‰∏ä $\sqrt{d_model}$ÔºåËøôÊòØÂéüËÆ∫Êñá‰∏≠ËßÑÂÆöÁöÑ„ÄÇÊñáÁ´†‰∏≠Ê≤°ÊúâÂØπËøô‰∏™ÂèòÈáèÁöÑËß£Èáä„ÄÇ</p>
<blockquote>
<p>In the embedding layers, we multiply those weights by $\sqrt{d_{model}}$</p>
</blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">input_vocab_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">               <span class="n">maximum_position_encoding</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">positional_encoding</span><span class="p">(</span><span class="n">maximum_position_encoding</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                            <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">enc_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">EncoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">rate</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">                       <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">seq_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># Â∞ÜÂµåÂÖ•Âíå‰ΩçÁΩÆÁºñÁ†ÅÁõ∏Âä†„ÄÇ</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># (batch_size, input_seq_len, d_model)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span><span class="p">[:,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">,</span> <span class="p">:]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">      <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">x</span>  <span class="c1"># (batch_size, input_seq_len, d_model)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="64-Ëß£Á†ÅÂô®">6.4. Ëß£Á†ÅÂô®</h3>
<p>Ëß£Á†ÅÂô®ÂíåÁºñÁ†ÅÂô®ÂèÇÊï∞Á±ª‰ºº„ÄÇ</p>
<ol>
<li>Â∞ÜËæìÂá∫Â∫èÂàóÂêåÊ†∑ËΩ¨Êç¢‰∏∫ÂêåÁª¥Â∫¶ËØçÂµåÂÖ•</li>
<li>Âä†‰∏ä‰ΩçÁΩÆÁºñÁ†Å</li>
<li>ÂíåÁºñÁ†ÅÂô®ÁöÑËæìÂá∫‰∏ÄÂêåËæìÂÖ•ÁªôÂ§ö‰∏™Ëß£Á†ÅÂô®Â±Ç</li>
</ol>
<p>Âú®Ë∞ÉÁî®Êó∂Ôºå<code>enc_output</code> ÊòØÊù•Ëá™ÁºñÁ†ÅÂô®Â±ÇÁöÑËæìÂá∫„ÄÇ</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">               <span class="n">maximum_position_encoding</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="nb">super</span><span class="p">(</span><span class="n">Decoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">positional_encoding</span><span class="p">(</span><span class="n">maximum_position_encoding</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">dec_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">DecoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">rate</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">                       <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">           <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">seq_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">attention_weights</span> <span class="o">=</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, d_model)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span><span class="p">[:,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">,</span> <span class="p">:]</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">      <span class="n">x</span><span class="p">,</span> <span class="n">block1</span><span class="p">,</span> <span class="n">block2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec_layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                             <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      
</span></span><span class="line"><span class="cl">      <span class="n">attention_weights</span><span class="p">[</span><span class="s1">&#39;decoder_layer</span><span class="si">{}</span><span class="s1">_block1&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">block1</span>
</span></span><span class="line"><span class="cl">      <span class="n">attention_weights</span><span class="p">[</span><span class="s1">&#39;decoder_layer</span><span class="si">{}</span><span class="s1">_block2&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">block2</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># x.shape == (batch_size, target_seq_len, d_model)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">attention_weights</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="7-ÂàõÂª∫-transformer">7. ÂàõÂª∫ Transformer</h2>
<p>Â∞ÜÁºñÁ†ÅÂô®ÂíåËß£Á†ÅÂô®ÁªÑÂêàËµ∑Êù•ÔºåËøûÊé•ÊúÄÂêéÁöÑÁ∫øÊÄßËæìÂá∫Â±ÇÔºåÂ∞±ÂæóÂà∞‰∫ÜÊï¥‰ΩìÁöÑ TransformerÔºö</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Transformer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">input_vocab_size</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">               <span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">pe_input</span><span class="p">,</span> <span class="n">pe_target</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="nb">super</span><span class="p">(</span><span class="n">Transformer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                           <span class="n">input_vocab_size</span><span class="p">,</span> <span class="n">pe_input</span><span class="p">,</span> <span class="n">rate</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                           <span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">pe_target</span><span class="p">,</span> <span class="n">rate</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">final_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">enc_padding_mask</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">           <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">dec_padding_mask</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">enc_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">enc_padding_mask</span><span class="p">)</span>  <span class="c1"># (batch_size, inp_seq_len, d_model)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># dec_output.shape == (batch_size, tar_seq_len, d_model)</span>
</span></span><span class="line"><span class="cl">    <span class="n">dec_output</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">tar</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">dec_padding_mask</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="n">final_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_layer</span><span class="p">(</span><span class="n">dec_output</span><span class="p">)</span>  <span class="c1"># (batch_size, tar_seq_len, target_vocab_size)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">final_output</span><span class="p">,</span> <span class="n">attention_weights</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="8-Â∞èÁªì">8. Â∞èÁªì</h2>
<p>Âà∞Ê≠§‰∏∫Ê≠¢ÔºåÊàë‰ª¨Â∑≤ÁªèÊèèËø∞‰∫Ü Transformer ÁöÑÊï¥‰∏™Ê®°ÂûãÊê≠Âª∫ËøáÁ®ãÔºåÂπ∂ÈÄêÂ±ÇÈÄêË°åÂú∞Ëß£Èáä‰∫ÜÂÖ∂Ê≠£Âêë‰º†Êí≠ÁöÑÂéüÁêÜÂíåÁªÜËäÇ„ÄÇÊú¨Êñá‰ªçÊú™ËÆ≤Âà∞ÁöÑÊòØÔºö</p>
<ul>
<li>Â¶Ç‰ΩïËÆ≠ÁªÉ‰∏Ä‰∏™TransformerÔºö
<ul>
<li>ÂâçÁûªÈÅÆÊå°ÂíåÂ°´ÂÖÖÈÅÆÊå°Â¶Ç‰Ωï‰ΩøÁî®„ÄÇ</li>
<li>Ë∂ÖÂèÇÊï∞Â¶Ç‰ΩïÈÖçÁΩÆ„ÄÇ</li>
<li>Â¶Ç‰ΩïËÆæËÆ°ÊçüÂ§±ÂáΩÊï∞„ÄÇ</li>
<li>Â¶Ç‰Ωï‰ºòÂåñÂíåËØÑ‰º∞„ÄÇ</li>
</ul>
</li>
</ul>
<p>ÂêéÁØáÂ∞ÜÁªìÂêàÂÆû‰æãËØ¶ÁªÜÊèèËø∞Ëøô‰∫õÂÜÖÂÆπ„ÄÇ</p>

</section>


    <footer class="article-footer">
    

    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>Licensed under CC BY-NC-SA 4.0</span>
    </section>
    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.css"integrity="sha256-J&#43;iAE0sgH8QSz9hpcDxXIftnj65JEZgNhGcgReTTK9s="crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.js"integrity="sha256-InsNdER1b2xUewP&#43;pKCUJpkhiqwHgqiPXDlIk7GzBu4="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/contrib/auto-render.min.js"integrity="sha256-y39Mpg7V3D4lhBX4x6O0bUqTV4pSrfgwEfGKfxkOdgI="crossorigin="anonymous"
                defer
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.querySelector(`.article-content`), {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ]
        });})
</script>
    
</article>

    

    

<aside class="related-content--wrapper">
    <h2 class="section-title">Related content</h2>
    <div class="related-content">
        <div class="flex article-list--tile">
            
                
<article class="has-image">
    <a href="/p/transformer-from-zero-4/">
        
        
            <div class="article-image">
                <img src="/p/transformer-from-zero-4/the_transformer.02a726e225f7010356c7d65bfb3ee8d5_hu9dc15172e42e840ef18a078a4efb196f_44824_250x150_fill_box_smart1_3.png" 
                        width="250" 
                        height="150" 
                        loading="lazy"
                        alt="Featured image of post ‰ªé 0 ÂºÄÂßãÂ≠¶‰π† Transformer ÊãæÈÅóÔºöÊñáÁ´†Êú¨Ë∫´ÁöÑ‰∏éËß£Èáä"
                        data-key="transformer-from-zero-4" 
                        data-hash="md5-Aqcm4iX3AQNWx9Zb&#43;z7o1Q==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">‰ªé 0 ÂºÄÂßãÂ≠¶‰π† Transformer ÊãæÈÅóÔºöÊñáÁ´†Êú¨Ë∫´ÁöÑ‰∏éËß£Èáä</h2>
        </div>
    </a>
</article>

            
                
<article class="has-image">
    <a href="/p/transformer-from-zero-3/">
        
        
            <div class="article-image">
                <img src="/p/transformer-from-zero-3/the_transformer.02a726e225f7010356c7d65bfb3ee8d5_hu9dc15172e42e840ef18a078a4efb196f_44824_250x150_fill_box_smart1_3.png" 
                        width="250" 
                        height="150" 
                        loading="lazy"
                        alt="Featured image of post ‰ªé 0 ÂºÄÂßãÂ≠¶‰π† Transformer Áï™Â§ñÔºöTransformer Â¶Ç‰ΩïÁ©øÊ¢≠Êó∂Á©∫Ôºü"
                        data-key="transformer-from-zero-3" 
                        data-hash="md5-Aqcm4iX3AQNWx9Zb&#43;z7o1Q==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">‰ªé 0 ÂºÄÂßãÂ≠¶‰π† Transformer Áï™Â§ñÔºöTransformer Â¶Ç‰ΩïÁ©øÊ¢≠Êó∂Á©∫Ôºü</h2>
        </div>
    </a>
</article>

            
                
<article class="has-image">
    <a href="/p/transformer-from-zero-2/">
        
        
            <div class="article-image">
                <img src="/p/transformer-from-zero-2/the_transformer.02a726e225f7010356c7d65bfb3ee8d5_hu9dc15172e42e840ef18a078a4efb196f_44824_250x150_fill_box_smart1_3.png" 
                        width="250" 
                        height="150" 
                        loading="lazy"
                        alt="Featured image of post ‰ªé 0 ÂºÄÂßãÂ≠¶‰π† Transformer ‰∏ãÁØáÔºöTransformer ËÆ≠ÁªÉ‰∏éËØÑ‰º∞"
                        data-key="transformer-from-zero-2" 
                        data-hash="md5-Aqcm4iX3AQNWx9Zb&#43;z7o1Q==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">‰ªé 0 ÂºÄÂßãÂ≠¶‰π† Transformer ‰∏ãÁØáÔºöTransformer ËÆ≠ÁªÉ‰∏éËØÑ‰º∞</h2>
        </div>
    </a>
</article>

            
        </div>
    </div>
</aside>

     
    
        
    <div class="disqus-container">
    <div id="disqus_thread"></div>
<script type="application/javascript">
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "hugo-theme-stack" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>

<style>
    .disqus-container {
        background-color: var(--card-background);
        border-radius: var(--card-border-radius);
        box-shadow: var(--shadow-l1);
        padding: var(--card-padding);
    }
</style>

<script>
    window.addEventListener('onColorSchemeChange', (e) => {
        if (typeof DISQUS == 'object') {
            DISQUS.reset({
                reload: true
            });
        }
    })
</script>

    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2019 - 
        
        2022 Lilith Sangreal
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.13.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
    

        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
